--- 
title: "D-score for measuring development of children 0-4 years"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, book_MG.bib]
biblio-style: apalike
link-citations: yes
description: "D-score I: Measurement"
---
```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```

```{r include=FALSE}
library(ggplot2)
knitr::opts_chunk$set(cache = TRUE)
ggplot2::theme_set(theme_light())
```

# Preface {-}

This is an introductory booklet on the measurement of child
development by means of the D-score. The D-score is a one-number
summary that quantifies generic neurocognitive development for
children with ages 0-4 years.

This is the *first* in a series of three booklets. The series consists
of the following titles:

1. [D-score for measuring development of children 0-4 years](https://stefvanbuuren.github.io/dbook1/)
2. [D-score for international comparisons](https://stefvanbuuren.github.io/dbook2/)
3. D-score for creating better instruments


<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Introduction {#intro}

## First 1000 days

## Relevance of child development

## Advantages and limitations of stunting

## Measuring neurocognitive development


<!--chapter:end:Rmd/01-intro.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Short history {#ch:history}

## What is child development?

In contrast to concepts like height or temperature, it is unclear what
exactly constites child development. One of the first rigorous studies
in the field [@SHIRLEY1931] was executed under the explicit aim 

> ... that the many aspects of development, anatomical, physical, 
> motor, intellectual, and emotional, be studied simultaneously.

Shirley gave empirical operationalizations of each of these
domains of development. 


```{r shirleyplot, echo = FALSE, fig.cap = '(ref:shirleyplot)', out.width='80%', fig.align='center'}
knitr::include_graphics("fig/shirley-motor.png")
```
(ref:shirleyplot) Gross motor development as a sequence of milestones. Source: @SHIRLEY1933.

Certain domains advance through a fixed sequence. Figure
\@ref(fig:shirleyplot) illustrates the various stages needed for
going from a *fetal posture* to *walking alone*. The ages are
indicative when these events happen, but there is a large variation in
timing between infants.

@GESELL1943 (p. 88) formulated the following definition of development:

> Development is a continuous process that proceeds stage by stage in
> an orderly sequence. 

Gesell's definition emphasizes that development is a continuous
process. The stages are useful as indicators to infer the level of
maturity, but are of limited interest by themselves.

@LIEBERT1974 (p. 5) emphasized that development is not a phenomenon
that unfolds in isolation.

> Development refers to a process in growth and capability over 
> time, as a function of both maturation and interaction with 
> the environment.

@CAMERON2012 (p. 11) defined an end-point of development, as follows:

> "Growth" is defined as an increase in size, while "maturity" or 
> "development" is an increase in functional ability...The endpoint
> of maturity is when a human is functionally able to procreate 
> successfully ... not just biological maturity but also behavioral
> and perhaps social maturity.

@BERK2013 (p. 30) presented a dynamic systems perspective on
child development as follows:

> Development cannot be characterized as a single line of change, 
> and is more like a web of fibers branching out in many directions,
> each representing a different skill area that may undergo both
> continuous and stagewise transformation.

There are many more definitions of child development. The ones given
here just illustrate the main points of view in the field.

## Theories of child development

The field of child development is huge and spans multiple academic
disciplines. This short overview therefore cannot do justice to
the enormous richness. Readers new to the field might orient
themselves by browsing through an introductory academic title (e.g.
@SANTROCK2010, @BERK2013), or by searching for the topic of interest
in an encyclopedia (e.g. @SALKIND2002).

The introductions by @SANTROCK2010 and @BERK2013 both distinguish
major theories in child development according to how each answers
to following three questions:

* *Continuous or discontinuous?*

Does development evolve gradually as a continuous process 
or are there qualitatively distinct stages, with jumps occurring 
from one stage to another?

Many stage-based theories of human development have
been proposed over the years: social and emotional development by
psychosexual stages of development proposed by Freud and furthered by
Erikson [@ERIKSON1963], Kohlberg's six stages of moral development
[@KOHLBERG1984] and Piaget's cognitive development theory
[@PIAGET1969]. Piaget distinguishes four main periods throughout
childhood. The first period, the *sensimotor period* (approximately
0-2 years), is subdivided into six stages. When taken together these
six stages describe "the road to conceptual thought". Piaget's stages
are qualitatively different, and aim to unravel the mechanism in
intellectual development.

On the other hand, Gesell and others emphasize development as a 
continuous process. @GESELL1943 (p. 88) says:

> A stage represents a degree or level of maturity in the cycle 
> of development. A stage is simply a passing moment, while 
> development, like time, keeps marching on.


* *One course or many?*

Stage theorists assume that children progress sequentially through 
the same set of stages. This assumption is also explicit in the 
work of Gesell.

The ecological and dynamic systems theories view development as
continuous, though not necessarily progressing in an orderly fashion,
so there may be multiple ways to reach the same point. Figure
\@ref(fig:dynamic) illustrates that the path taken by a given child
will depend on the child's unique combination of personal and
environmental circumstances, including cultural diversity in
development.

```{r dynamic, echo = FALSE, fig.cap = '(ref:dynamic)', out.width='80%', fig.align='center'}
knitr::include_graphics("fig/dynamic.png")
```

(ref:dynamic) A representation of the dynamic systems viewpoint on how different combinations of skills may lead to the same end point using different paths. Source: @BERK2013.

* *Nature or nurture?*

Are genetic or environmental factor more important for influencing
development? Most theories generally acknowledge the role of both, but
differ in emphasis. In practice, the debate centers on the question
how to explain individual differences.

Maturation usually defined as the genetically determined, naturally
unfolding course of growth, much like a flower. Some theorists
emphasize that differences in development are innate and stable over
time, but that there may be differences in speed. Others argue that
individual differences are primarily driven by environmental factors,
and changing these factors could very well impact child development.

The answer --- if there is one --- in this stability-versus-plasticity
debate has important practical consequences. If we believe that
differences are natural and stable, then it may not make sense trying
to change the environment, as the impact on development is likely to
be small. On the other hand, if we view development as plastic, then
improving the environment may have substantial pay-offs in terms of
improved development.

## Example of motor development

```{r echo = FALSE, warning = FALSE}
pkg <- c("knitr", "tidyr", "dplyr", "ggplot2")
loaded <- sapply(pkg, require, character.only = TRUE, 
                 warn.conflicts = FALSE, quietly = TRUE)
options(knitr.kable.NA = "?")
```

For illustration, we use data on locomotor development collected in
the classic study on child development among 25 babies by
@SHIRLEY1931. Starting at ages around 13 weeks, a graphic record of
the baby's walking was obtained as follows. The investigator lays out
a white paper of twelve inches wide on the floor of the living room,
and lightly greases the soles of the baby's feet with olive oil. The
baby was invited to "walk" on the sheet. Of course, very young infants
need substantial assistence. Footprints left were later colored by
graphite and measured. Measurements during the first year were
repeated every week or bi-weekly.

```{r shirley, echo = FALSE}
shirley <- data.frame(
  name = c("Martin", "Carol", "Max", "Virginia Ruth", "Sibyl",
  "David", "James D.", "Harvey", "Winnifred", "Quentin", 
  "Maurice", "Judy", "Irene May", "Peter", "Walley", "Fred",
  "Donovan", "Patricia", "Torey", "Larry", "Doris"), 
  sex = c("boy", "girl", "boy", "girl", "girl",
          "boy", "boy", "boy", "girl", "boy",
          "boy", "girl", "girl", "boy", "boy", "boy",
          "boy", "girl", "boy", "boy", "girl"),
  stepping = c(15, 15, 14, NA, NA, 19, 19, 14, 15, 15,
  18, 18, 19, 15, 18, 15, NA, 15, NA, 13, NA),
  standing = c(NA, 19, NA, 21, 22, 27, 30, 27, 30, 23,
  23, 29, 34, 29, 33, 32, 23, 30, 21, 41, 23),
  walk_help = c(21, 37, 25, 41, 37, 34, 45, 42, 41, 38,
  45, 45, 45, 49, 54, 46, 50, 45, 72, 54, 44),
  walk_alone = c(50, 50, 54, 54, 58, 60, 60, 62, 62, 64,
  66, 66, 66, 66, 68, 70, 70, 70, 74, 76, NA))
kable(shirley, 
      col.names = c("Name", "Sex", "Stepping", "Standing", 
                    "Walking with help", "Walking alone"))
```

: (\#tab:shirley) Age at beginning stages of walking (in weeks) 
for 21 babies [@SHIRLEY1931, Appendix 8].

Table \@ref(tab:shirley) lists the age (in weeks) of the 21 babies when
they started, respectively, stepping, standing, walking with help, and
walking alone. Question marks indicate missing data. A question mark
in the first column the babies were already stepping when the
observation started (Virginia Ruth, Sibyl, Donovan and Doris). Max and
Martin, who have a question mark in the second column, skipped
standing and went directly from stepping to walking with help. Doris
has a question mark in the last column, because she died before she
could walk alone.

```{r stepplot, echo = FALSE, fig.asp = 0.6, fig.cap = '(ref:stepplot)'}
d <- shirley %>%
  mutate(name = factor(name, as.character(name))) %>%
  gather(key = "stage", value = "age", -name, -sex) %>%
  mutate(
    stage = factor(stage, unique(stage)),
    score = rep(1:4, each = 21))
ggplot(d, aes(age, stage, group = name, colour = name)) +
  geom_step() + 
  geom_point() + 
  theme_light() + 
  facet_wrap(~ name, nrow = 3) +
  guides(colour = FALSE) + 
  labs(x = "Age (weeks)", y = "Stage")
```

(ref:stepplot) Staircase plot indicating the age at which each baby 
achieve a new milestone of gross-motor functioning.

Figure \@ref(fig:stepplot) is a visual representation of the
information in Table \@ref(tab:shirley). Each data point is the age of
first occurence of the next stage. Before that age, the baby is
supposed to be in the previous stage, so once the next stage occurs,
there is a jump to the next level.

The figure makes it easy to spot the quick walkers (Martin, Carol) and
slow walkers (Patricia, Torey, Larry). Furthermore, we may also spot 
children who remain a long time in a particular stage (Torey, Larry)
or who jump over stages (Martin, Max).

For ease of plotting, the categories on the vertical axis are equally
spaced. The height of the jump from one stage to the next has no
interpretation. In particular, the vertical distance does not tell us
how difficult it is to achieve the next stage. Instead, difficulty
corresponds to the length of the line in the horizontal direction
between stages. For example, on average the line for `stepping` is
rather short in all plots, so going from `stepping` to `standing` is
relatively easy.

The figure presents data from only those visits where a jump occurred.
The number of house visits made during ages 0-2 years was far higher.
@SHIRLEY1931 actually collected data from 1370 visits, whereas Figure
\@ref(fig:stepplot) plot just the 76 visits with jumps. Thus, to
obtain these individual curves like these data collection needs to be
intense and costly.

## Typical questions asked in child development {#sec:questions}

Child development is very relevant for answering clinical, policy and
public health questions. On the level of the individual child, we pose questions like:

- What is your gain in development since your last visit? 

- What is the difference in development between you and your friend 
of the same age?

- How does your development compare to a norm?

The identification of determinants or effects of interventions typically
formulate questions at the group level. Some examples are:

- What is the effect of this intervention on child development?

- What is the difference in child development between these two groups?

Questions on the level of the population health levels include:

- What is the change in average child development since the last
measurement?

- What was the effect of implementing this policy on child development?

- How does this country compare to other countries in terms of child development?

Note that all questions compare the amount of child development between 
groups and/or time points. A few questions compare development for the same
child/group/population at different ages. Some others compare
development within the same age across different children, group 
or populations.


## Three ways to quantify child development {#sec:threeways}

This section distinguished three different methods to quantify child
development: age-based, score-based and unit-based measurement.

### Age-based measurement of development {#sec:agebased}

The motivation for measuring child development is to be able to
describe the behavior expected at a selected age. @GESELL1943 (p. 89)
formulates this goal as follows:

> We think of behavior in terms of age, and we think of age in terms
> of behavior. For any selected age it is possible to sketch a portrait
> which delineates the behavior characteristics typical of the age.

@STOTT1967 (p. 22) observed that it is impossible to define a scale
for measuring child development:

> When development appears as a change in kind, that is, when the 
> change consists of a series of qualitatively different events,
> or features, or "stages", it is not amemable to measurement
> by use of any standard scale of units.

As a solution Stott suggested using the "invariable sequence" of
successive stages as the basis for the assessment of the individual's
status. Stott argues that such sequences are fairly well established
for physical activity. He admits though that such stages are less
clear for the acquisition of speech and other social skills.

Since age and development are so intimately related, the *difficulty*
of developmental a given milestone is traditionally expressed in terms
of the age at which children achieve the milestone. For example,
@STOTT1967 (p. 25) defines the *age equivalent* and its use for
measurement, as follows:

> The age equivalent of a particular stage is simply the average age 
> at which children reach that particular stage. A set of age 
> equivalents corresponding to a series of stages can be made to 
> function as a scale for individual assessment.

Alternatives to the age equivalents include the ages at which 10, 50
or 90 percent of the children achieve the milestone. This line of
reasoning has led to the widely used concept of `developmental age` as
a measure of a child's development (in body size or motor skill or
psychological function) expressed in terms of age norms.

Age-based measurement was once the dominant paradigm for measuring
child development. It is easy to understand, but is not without 
some problems and limitations.

1. Age-based measurement does not tell us what is normal for a child
at a given age. We can properly infer whether a child is early or late
for a given milestone. However, this does not give us insight which
behaviors are characteristic at the child's age.

2. Age-based measurement cannot exists without an age norm. When there
is no norms, we cannot quantify development. Age-based measurement
does not separate quantification of development from evaluation of 
development.

3. Age-based measurement only works at the item level, and is 
cumbersome to apply with multiple items.

### Score-based measurement of development {#sec:scorebased}

A second approach to measurement is to administer multiple items to
the child, and and compute the total number of PASS responses as a
measure of child's development. Items can be ordered in difficulty, so
one may skip items that are too easy, and stop when items become too
difficult. Since different children get different sets of items, one
cannot simply interpret the sum score of a measure of development.
Most instruments describe corrections that should be applied,
typically under the assumption that the child would have passed all
"too easy" items and failed on all "too difficult" items. This
procedure is typically repeated for different domains, e.g. motor,
cognitive, and so on.

Score-based measurement is the dominant approach, but is not without
conceptual and logistical issues.

1. The total scores calculated by different instruments are based on
different sets of items, and hence cannot be compared. In addition,
instruments use their own age norms, but these do extend to norms for
measurements made by other instruments.

2. Domains are hard to separate. For example, some cognitive items tap
into fine motor capabilities, and vice versa. There are different ways
to define domains, so domain interpretation varies by instrument.

3. Administration of a full test may take substantial time. The
materials are often proprietary and sometimes costly.

### Unit-based measurement of development {#sec:unitbased}

Unit-based measurement starts from the premise that the measurement
scale must have a constant unit. If that holds, then the same
difference between two values has the same interpretation anywhere on
the scale. Familiar examples of such scales includes temperature and
dates. For example, the difference between two dates corresponds to
the same amount of time, irrespective of whether this is now, in the
past or in the future. The interval scale has a fixed unit and an
arbitrary zero.

In the ideal situation, we would have a unit for child development.
Let us name this unit *D*, for development. Unit *D* should have the
following desirable properties:

- Difference between two *D*-scores measured on the same child at
different ages quantifies the amount of development during the
interval

- Difference between the *D*-score measured on two different children
of the same age quantifies the difference in development between them

- Comparing the *D*-score to an age-dependent reference identifies
abnormal development

The interpretation of the difference between two *D*-score is the same
across the entire scale, just like differences in height or weight.
Note that the unit would allow us to answer all questions raised in section @\ref(sec:questions).

The development of a unit for development is still in its infancy.
However, if we succeed in creating an interval scale for development,
then an enormous arsenal of technique developed for quantitative
variables opens up to measure, track and analyze child development.

### Why we need unit-based measurement {#sec:whyunit}

This section reviewed age-based, score-based and unit-based approaches
to the measurement of child development. Age-based measurement
expresses development in age-equivalents, whose precise definition
depends on the reference population. Score-based measurement
quantifies development by summing the number of passes, but different
instruments make different selections of items, so the measurements
are unique to the instruments, and cannot be compared across
instruments. Neither approach provides a unit for child development.

In order to make progress, what we need is the definition of a unit for
child developent, and an operationalization how each measurement item
related to the unit. If we success in this, we are able to construct
different instruments that yields measurement in a common metric. The
next chapter will introduce the basic concepts for this new approach.



<!--chapter:end:Rmd/02-history.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# New model to quantify child development {#ch2:newmodel}

Chapter \@ref(ch:history) introduces the age-based, score-based and
unit-based approaches to measurement of child development. This
chapter introduce the basic concepts for the new unit-based approach.

## The latent variable, and its role in measurement

In this booklet we define measurement as 
*the process of locating children and items on a line.* The line can
represents a latent variable, a continuous construct that defines the
different poles of the concept that we want to measure. In our case,
the concept is *child development*. Other constructs, like *height*,
*temperature* or *happiness* would be equally valid constructs. In
practice, the position of the items on the line will be fixed when the
measurement instrument is created. Application of the instrument
involves placing children onto the line given their scores on one or
more of the items, which is the more usual activity that we describe
as "measurement". Realize however that both steps are needed.

A latent variable ranges from low to high, and has a constant unit.
Thus, interpretation of the same difference is identical across the
entire scale. A latent variable cannot be measured directly. It is a
theoretical construct. However, we may be able to actually measure
variables (test items) that are in some way related to the latent
variable. For example, we may have the child's scores on a set of
tasks, such as "stacking two blocks". The way in which the measured
variables are related to the latent variables is called the
*measurement model*.

Some measurement models attempt to explain systematic patterns in the
observed data through their relation to a single underlying variable.
For example, we may find that the observed data are highly correlated,
but that this correlation disappears within groups of children that have
the same value on the latent variable. In that case, we have absorbed
the common information in the variables into a single score that
captures the relevant information.

Probabilistic measurement models express the probability of passing an
item as a function of the difference between the person's ability and
the item's difficulty. A person with low ability will almost surely
fail a difficult item, whereas a highly able person will almost surely
pass an easy item. If we know the score on one or more items, and the
difficulties of these items, we may calculate the position of the
person on the latent variable.

### Criteria for invariant measurement

Measurement is the process of assigning numbers by rules to a set of
persons or objects. This definition is a little liberal. In order to
be useful the process of assigning numbers must be bound by some
imperatives. In this booklet, we strive to achieve *invariant
measurement*, a very strict form of measurements that is subject to
the following requirements (@ENGELHARD2013, p. 14):

1. *Item-invariant measurement of persons*: The measurement of persons
must be independent of the particular items that happen to be used for
the measuring.

2. *Non-crossing persons response functions*: A more able person must
always have a better chance of success on an item that a less able
person.

3. *Person-invariant calibration of test items*: The calibration of
the items must be independent of the particular persons used for
calibration.

4. *Non-crossing item response functions*: Any person must have a
better chance of success on an easy item than on a more difficult
item.

5. *Unidimensionality*: Items and persons must be simultaneously
located on a single underlying latent variable.

A statistical model that conforms to these five requirements is said
to be an *ideal-type model*. There are only very few ideal-type
models. An ideal-type model isn't changed to fit the data, but the
data (items and persons) are selected to fit the ideal-type model.

The need for the five requirements for invariance is not universally
shared. In particular, a substantial group of statisticians questions
the need for requirements 2 and 4, especially the words "always" and
"any", and may opt for more flexible models that do not strictly
adhere to the invariance conditions 2 and 4. There are also more
flexible models that assume a multi-dimensional instead of a
unidimensional latent variable. Some investigators question all
requirements, and would rather not be restricted and place a high
value to a good fit to all data.

### Item response functions

Let $\beta_n$ be the true (but unknown) developmental score of a child
at the time of measurement. The more generic term is the child's
*ability*. The *item response function* describes the probability of
passing an item as a function of ability. In general, we expect
that this probability increases with ability (requirement 2). Note
that this formulation differs from that given in Section
\@ref(agebased), where the probability was said to increase in age,
not ability. We will address this crucial difference in more detail in
Section \@ref(comparisonagebased).

```{r irfplot, echo = FALSE, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:irfplot)'}
pkg <- c("ggplot2", "RColorBrewer")
loaded <- sapply(pkg, require, character.only = TRUE, 
                 warn.conflicts = FALSE, quietly = TRUE)
options(knitr.kable.NA = "?")

x <- seq(-5, 5, 0.25)
items <- data.frame(
  Items = c(rep(LETTERS[1:5], times = c(4, 2, length(x), length(x), length(x)))),
  beta = c(-5, 1, 1, +5,  -5,  +5, x, x, x),
  pass = c( 0, 0, 1,  1, 0.3, 0.3,
           plogis(x),
           plogis(0.6 * (x + 1)),
           smooth.spline(x = x, y = plogis(c(x[1:15], rep(x[16], 10), x[26:41])), df = 8)$y))
ggplot(items, aes(x = beta, y = 100 * pass, group = Items, colour = Items)) +
  geom_line(lwd = 0.75) + 
  scale_x_continuous("Child's ability (logits)", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(palette = "Set1", labels = c("A: Step", "B: Constant", "C: Logistic", "D: 2PL", "E: Monotone")) + 
  theme_light() + 
  theme(legend.position = c(0.05, 0.95), legend.justification = c(0, 1))
```

(ref:irfplot) Item response functions for five hypothetical items,
each demonstrating a positive relation between ability and probability
to pass.

Ability and passing probability can be related in many ways. Figure
\@ref(fig:irfplot) illustrates the item response function of five
hypothetical test items A-E. Let us consider each of these function.

- A: Item A has step function, so all children with an ability < 1
logit fail, and all children with ability > 1 pass. This is the ideal
item for discriminating children that with abilities below and above 1
logit. The step function is widely used in sports. In a high-jumping
tournament, the bar is set very high in order to be able to
discriminate the best athletes. Note that the step function can only
test whether ability is below or above a specific level. It does
discriminate abilities at other levels.

- B: For item B, the probability of passing is constant at 30 percent.
This 30 percent is not related to ability. This item does not measure
ability, and only adds to the noise. It is a bad item for measurement.

- C: Item C has a smoothly increasing logistic function. If we know
ability $\beta$, the probability of passing can be calculate by the
standard logistic function $f(\beta) = e^\beta/(1+e^\beta)$. This
item can discriminate best around the point at which the probability
of passing is 0.5. The level is called the difficulty. Unlike the 
step function, this item can also discriminate abilities in the
neighborhood of the difficulty. 

- D: Item D is also a smoothly increasing logistic function, but it
has an extra parameter that allows it to vary its slope (or
discrimination). The extra parameter can be the item steeper (more
discriminatory) than the green curve, in the limit approaching a step
curve. It can also become shallower (less discriminatory) than the
green curve (as plotted here), in the limit approaching a constant
curve. Thus, item D is more general that items A, B or C.

- E: Item E is even more general in the sense that it need not be
logistic, but can be any monotonically increasing function. As
plotted, the item is insensitive to abilities between -1 and 0 logits,
and more sensitive to abilities of 0 to 2 logits.

These are just some examples of how the relation between the child's
ability and passing probability could look. In practice, the curves
need not start at 0 percent or end at 100 percent. They could also be
U-shaped, of have other non-monotonic forms. See @COOMBS1964 for a
thorough overview of such models. Here we restrict to increasing
functions so as to conform to invariance requirement 2.

### Person response functions

We now switch the roles of persons and items, and construct a function
that tells us how likely it is that a single person can pass an item, 
or more commonly, a set of items. 

<!-- Let $\delta_i$ be the true (but unknown) *difficulty* of an item. The -->
<!-- *person response function* is the probability that a single person passes  -->
<!-- each of a set items of varying difficulties.  -->

Let us continue with items A, C and D from Figure \@ref(fig:irfplot), and 
calculate the response function for three children, respectively with 
abilities $\beta_1 = -2$, $\beta_2 = 0$ and $\beta_3 = 2$.

```{r prfplot, echo = FALSE, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:prfplot)'}
x <- c(seq(-5.00, -2.25, 0.25), -2.001, -2, -1.999, 
       seq(-1.75, -0.25, 0.25), -0.001,  0,  0.001,
       seq( 0.25,  1.75, 0.25),  1.999,  2,  2.001,
       seq( 2.25,  5.00, 0.25))
A1 <- c(rep(1, 23), 0.5, rep(0, 23))
C1 <- 1 - plogis(x)
D1 <- 1 - plogis(0.6 * (x + 1))
ACD1 <- (A1 + C1 + D1) / 3

A2 <- c(rep(1, 33), 0.5, rep(0, 13))
C2 <- 1 - plogis(x - 2)
D2 <- 1 - plogis(0.6 * (x - 1))
ACD2 <- (A2 + C2 + D2) / 3

A3 <- c(rep(1, 13), 0.5, rep(0, 33))
C3 <- 1 - plogis(x + 3)
D3 <- 1 - plogis(0.6 * (x + 4))
ACD3 <- (A3 + C3 + D3) / 3

data <- data.frame(delta = x,
                   person = rep(c("-2", "0", "+2"), each = 47),
                   pass = c(ACD3, ACD1, ACD2))
ggplot(data, aes(x = delta, y = 100 * pass, group = person, colour = person)) +
  geom_line(lwd = 0.75) + 
  scale_x_continuous("Item difficulty (logits)", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(name = "Person ability", palette = "Set1", limits = c("-2", "0", "+2")) + 
  theme_light() + 
  theme(legend.position = c(0.8, 0.6), legend.justification = c(0, 0)) +
  annotate("text", x = -4.5, y = 15, label = "Easy items", fontface = "bold") + 
  annotate("text", x =  4.5, y = 15, label = "Hard items", fontface = "bold")
```

(ref:prfplot) Person response functions for three children with abilities 
-2, 0 and +2, using a small test of items A, C and D.

Figure \@ref{fig:prfplot} presents the person response functions from
three persons with abilities of -2, 0 and +2 logits. The functions are
calculated as the average of response probabilities on items A, C and
D. Thus, on average, we expect that child 1 will pass an easy item of
difficulty -3 in about 60 percent of the time, whereas for an
intermediate item of difficulty of -1 the passing probility would be
10 percent. For child 3, with a higher ability, these probabilities
are quite different: 97% and 90%. The substantial drop in the middle
of the curve is caused by the step function of item A. 

Requirement 2 states that the success probability should be higher for
persons with a higher ability level. This is indeed the case here, but
there are also item response functions for which requirement 2 does
not hold.

### What is a test?

A set of items forms a test. The primary reason for administering a
test rather than a separate item is to improve the precision of the
measurement. The scores on the set of items (rather than the score on
a single item) can be combined into an overall score. Of course,
combining scores can only make sense if these items measure the same
underlying construct.

In principle, the five items A-E in Figure \@ref(fig:irfplot) could
form a test. This would not be an ideal test though, since this test
would violate requirement 4. We know that the difficulty of item A is
equal to +1 logits, and the difficulty of item C is 0 logits, so item
C is easier than item A. Requirement 4 says that persons should have a
higher chance of passing C. This is true indeed for persons having an
ability lower than +1 logits. However, for a person with ability +2
logits, the probability of passing A is higher than passing C, hence
requirement 4 does not hold for any test that holds both items A and 
C.


### Interval scale

The important property is that $\beta_1$, $\beta_2$ and $\beta_3$ are
all on the same scale, and hence can be compared in a sensible way. In
particular, suppose that $\beta_2 - \beta_1 = \beta_3 - \beta_2$, we
might say that the difference between ability $\beta_1$ and $\beta_2$
is the same the difference between abilities $\beta_2 - \beta_3$. This 
is the essential property of an interval scale.



### Family of item response theory models

*Ideal-type models*:

1. Guttman scalogram model (@GUTTMAN1950)

2. Rasch model (@RASCH1960) and extensions (@WRIGHT1982, @ANDRICH1988)

3. Mokken scaling model (@MOKKEN1971).

The Guttman and Mokken model yield an ordinal latent scale, while the 
Rasch model yields an interval scale (with a constant unit).


## Comparison to classic age-based approach {#comparisonagebased}

EXAMPLES OF AGE-BASED MEASUREMENT

Let the $Y_j$ contain the scores on the $j$-th developmental item, where $j = 1, \dots, p$. 
For the moment, let us assume that all items are binary, so that 
$Y_j = 0$ indicates a fail, and $Y_j = 1$ indicates a pass. 
Suppose we are interested in studing the relationship between age, denoted by 
variable $X$, and development as measured through items $Y_1, \dots, Y_p$.

The joint distribution $P(Y_1, \dots, Y_p, X)$ contains all relevant 
information for this problem. Age-based measurement is an attempt to model 
this joint distribution by breaking it down into $p$ conditional distributions:
$$
P(Y_1 | X)\\
\vdots\\
P(Y_p | X)\\
$$

each of which describes how the probability of passing changes with age. 
For example, @DRACHLER2007 formulated the model as a logistic regression 
model on the logarithm of age:

$$ 
\ln \frac{P(Y_j=1)}{P(Y_j=0)} = \alpha_j + \beta_j\ln X
$$

For this model, the age at which 50\% of the children pass item $j$ 
can be calculated as to $\exp(-\alpha_j/\beta_j)$. Since older children are 
expected to be more mature, this parameter is typically 
interpreted as the difficulty of the item. The slope parameter 
$\beta_j$ indicates how rapidly the probability of passing 
rises with age. Items with high $\beta_j$ have a great power to discriminate 
developmental status well within a small age range. It is straightforward
to calculate any other age-percentiles, for example, the ages 
at which probabilities 10\% or 90\% of the sample pass the item.
Table~2 in @DRACHLER2007 reports these statistics for the Denver 
developmental test.

While the idea of breaking up the test into separate items
is productive, age-based measurement has severe weaknesses. 

1. The concepts of age and development are not separated, so we 
cannot interpret the difficulty of an item without age. 
It would be more convenient, and conceptually clearer, if 
item difficulty could be a free-standing concept.

2. The models are fitted separately for each $Y_j$. Nothing 
is specified how the items relate to each other, so in principle, 
any variable that changes with age (e.g. child had first birthday) could 
qualify as a developmental item. It would be better of the 
procedure would start from a model about how the items should 
relate to each other. 

3. The intercept and slope estimates are dependent on 
the sample. A sample consisting of children of low ability
would give different estimates than a sample of children with
high ability. Calibration of test items is not person-invariant. 
It would be preferable if the difficulty estimates
were independent of the sample used to estimate them. 

4. Because of the introduction of slopes in the logistic model
a more able person may have a lower success probability for some
items than a less able person. It would be preferable if 
more able persons have a better succes rate on all items.

<!--chapter:end:Rmd/03-comparisons.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Measurement model {#measurement} (SB)

## Guttman model 

## Rasch model

## Perfect symmetry

## Parameter separation

## The model as ideal

## Why the Rasch model?

### Specific objectivity (example)

### Simplicity

<!--chapter:end:Rmd/04-rasch.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Interpretation of item fit {#items} (IE)

## SMOCC data: design

To illustrate the interpretation of fit measures for the D-score we use the SMOCC study (Herngreen et al, 1993), which covers the age range 0-2 years. In the SMOCC study 57 items are asssesed to measure the D-score. 

```{r, include=FALSE}
library(ddata)
library(dmetric)
library(dscore)
library(sirt)
```


## Empirical and fitted item response curves

An imporant aspect of the Rasch analysis is the issue of model fit. Actually, for the Rasch model it is not the task of the model to account for the data, however it is the task of the data to fit the Rasch model. Accordingly, the model fit determines how well emprirical data meets the requirement of the Rasch model. The fit of the data to a Rasch model can be visually inspected by comparing the observed probability of endorsing an item to the fitted item response curve for endorsing the item. The fitted item response curve for each item $i$ is modeled as: $$P_{ni}= \frac{exp( \beta_{n} - \delta_{i} )}{1+exp(\beta_{n}-\delta_{i})}$$, where $\beta_n$ is the ability of person $n$ and $\delta_i$ is the difficulty of item $i$. In the Figure below, the item characteristics curve can be obverved for an example item "n26" and item "n40". It can be observed that for both items the observed data (orange line) fits nicely to the estimated item response curve (dashed line).  


```{r icc, include=FALSE, message=FALSE, warning=FALSE}

smocc <- get_gcdg(study="Netherlands 1", adm = TRUE)
smocc$age <- smocc$age/12
varlist <- prepare_items(study = "Netherlands 1")
equatelist <- prepare_equates(varlist)
model_name<- "smocc"
sm1 <- fit_dmodel(varlist=varlist,equate=equatelist, name = model_name)
plots <- plot_p_ability_item(data=smocc, model = sm1, metric="logit")
#plots <- plot_p_ability_item(data=smocc, model = sm1, metric="dscore")


## hier gaat het nog steeds verkeerd met het plotten van de pass voor ability (observed) abilities lijkt overschat in data in vergelijking tot difficulty in model.. 
# data <- smocc
# model <- sm1
#   data <- left_join(data, model$beta_l)
#     delta <- model$fit$item[,"b"]
#     names(delta) <- rownames(model$fit$item)
#     delta <- delta[items]
#     beta_breaks <- seq(-15,25,1)
#     xlim <-c(-15,25)
#     scale <- 1
#   items <- model$items
# 
# pass <- data %>%
#     gather(key = item, value = value, items) %>%
#     drop_na(item, value, b) %>%
#     mutate(bgp = cut(b, breaks = beta_breaks)) %>%
#     group_by(item, study, bgp) %>%
#     summarise(p = round(100 * mean(value, na.rm = TRUE)),
#               a = mean(age, na.rm = TRUE),
#               b = mean(b, na.rm = TRUE),
#               n = n()) %>%
#     ungroup %>%
#     mutate(rug = FALSE) %>%
#     left_join(ddata::get_itemtable(items), by = "item")

```


```{r echo=FALSE, message=FALSE, warning=FALSE}
plots[["n26"]]
plots[["n40"]]
```


## Item fit

The fit of the items evaluate the extent to which data performs with the construction of measurement. An assumption of the Rasch model is that items with a lower difficulty will always have a higher probability to pass in comparison to items with a higher difficulty level. Fit analysis evaluates the extend to which this is true for each item. Two types of item fit are distinguished: the item outfit and the item infit. The outfit evaluates the extent to which the responses to the items are consistent with the model. In other words wheter items with a lower difficulty also have a higher probability to pass. The outfit statistic is heavity infulenced by outlying responses that do not fit the expected pattern. The infit is the information weighted fit and is more sensitive to inlying, on-target, unexpected responses. 

To determine the fit of items to the model we compare the observed responses and the expected values. The observed response $x_{ni}$ of person $n$ on item $i$ can be $0$ or $1$. The expected response $P_{ni}$ is modelled as $$E_{ni}= \frac{exp( \beta_{n} - \delta_{i} )}{1+exp(\beta_{n}-\delta_{i})}$$. The difference between the observed and the expected responses are the residual errors. The item infit is the sum of the squared errors divided by the sum of the expected response variances $W_{ni}$. The expected response variance $W_{ni}$ can be obtained as $E_{ni}(1-E_{ni})$. The outfit is calculated as the sum of the squared standardizes errors. The residual errors are standardized by dividing by the expected binomial standard deviation: $$z_{ni} = \frac{x_{ni}-E_{ni}}{\sqrt{W_{ni}}}$$ 
Accordingly the infit and outfit are calculated as: $$Infit = \frac{\sum_{n}^N (x_{ni}-E_{ni})^2}{\sum_n^N W_{ni}}$$
$$Outfit = \frac{\sum_{n}^N z_{ni}^2}{N}$$

In the figure below an item with a large outfit is presented as well as an item with a large infit. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
N <- 500    # number of persons
I <- 5      # number of items
b <- seq( -2, 2, length=I)
th <- rnorm(n=N)
set.seed(121212)
dat <- sirt::sim.raschtype(th, b ,fixed.a=c(0,0,5,0,0)) #add a large positive slope for item 3
colnames(dat) <- paste0( "I", 1:I )
items <- colnames(dat)
dat$age <- rnorm(N, 1, 1)
dat$id <- 1:N
itemtable <- data.frame(item = items)
#2PL functie data maken (platte bijv sociall emo en hele stijlen)
model1 <- fit_raschmodel(data = dat, items = items, itemtable = itemtable,equate = NULL, age_unit = "years")
#model1$item_fit
#model1$beta_l
#outfit impute 1s for person with lower ability than item ability
plots3 <- plot_p_ability_item(data=dat,model=model1, metric = "logit")
plots3[[3]]

```


## Item information at a given ability

The item information can be calculated as the amount of psychometric information an item contains for a given ability. The formula for the item information is the first derivative of the item response curve and can be written as follows: $$I(\delta)=P_i(\delta)(1-P_i(\delta))$$ where $P_i(\delta)$ is the conditional probability of endorsing an item. For example for item n40 "Says three words" the $\delta_i$ equals $3.47$. The probability of endorsing this item for a person with an ability level of $2$ standard deviation above the mean is $$P_{ni}= \frac{exp(2 -  3.47)}{1+exp(2-3.47)}$$ $$P_{ni}= 0.19$$
So for an ability level of $2$ standard deviations above the mean $\beta_n=2$, item n40 has an information value of $$I(\delta)=0.19(1-0.19)$$ $$I(\delta)=0.15$$ 
In the Figure below, the item information curves for item n26 and n40 are displayed. The implications of the item information is that the amount of information an item provides is maximized around the item-difficulty parameter. 

```{r echo=FALSE, message=FALSE, warning=FALSE}

#item information curve
## bereken item info by difficulty
 info <- function(beta, delta) {(exp(beta-delta)/(1+exp(beta-delta)) * (1-exp(beta-delta)/(1+exp(beta-delta))))}
 delta <- sm1$fit$b["n26"]
 betar <- c(-7,2)
 beta = seq(betar[1], betar[2], length = 200)
 iteminfo26 <- data.frame(ability=beta,I=info(beta,delta))

 delta <- sm1$fit$b["n40"]
 betar <- c(-2,7)
 beta = seq(betar[1], betar[2], length = 200)
 iteminfo40 <- data.frame(ability=beta,I=info(beta,delta))


 iteminfo26$item <- "n26"
 iteminfo40$item <- "n40"
 df <- rbind(iteminfo26,iteminfo40)
 ggplot(df, aes(ability,I, group=item, color=item))+geom_line()+xlab("Ability")+ylab("Item information")

```


## Item information at a given age

```{r echo=FALSE}
#calculate_age_equivalents(model=sm1, p=50, reference=dscore::gcdg_reference)

```


<!--chapter:end:Rmd/05-items.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Interpretation of person fit {#persons} (IE)

## Empirical and fitted person response curves

## Person fit

The fit of the persons evaluates the extent to which the responses of any person conform to the Rasch model expectation. The Rasch model expects that a more able person has a greater probabilty to pass any item than a less able person. Fit analysis evaluates the extend to which this is true for any person. Two types of person fit are distinguished: the person outfit and the person infit. The outfit evaluates the extent to which the responses to of the persons are consistent with the model. In other words wheter persons with a lower ability also have a lower probability to pass items. The outfit statistic is heavily infulenced by outlying responses that do not fit the expected pattern. The infit is the information weighted fit and is more sensitive to inlying, on-target, unexpected responses. 

To determine the fit of persons to the model we compare the observed responses and the expected values. The observed response $x_{ni}$ of person $n$ on item $i$ can be $0$ or $1$. The expected response $E_{ni}$ is modelled as $$E_{ni}= \frac{exp( \beta_{n} - \delta_{i} )}{1+exp(\beta_{n}-\delta_{i})}$$. The difference between the observed and the expected responses are the residual errors. The person infit is the sum of the squared errors divided by the sum of the expected response variances $W_{ni}$. The expected response variance $W_{ni}$ can be obtained as $E_{ni}(1-E_{ni})$. The outfit is calculated as the sum of the squared standardizes errors accumulated over the items $L$ to evaluate the plausability of any person response. The residual errors are standardized by dividing by the expected binomial standard deviation: $$z_{ni} = \frac{x_{ni}-E_{ni}}{\sqrt{W_{ni}}}$$. Accordingly the infit and outfit are calculated as: $$Infit = \frac{\sum_{n}^L (x_{ni}-E_{ni})^2}{\sum_n^L W_{ni}}$$
   $$Outfit = \frac{\sum_{n}^L z_{ni}^2}{L}$$. 


## Ability estimation




## Measurement precision



## Distribution of ability against age



<!--chapter:end:Rmd/06-persons.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Validity {#validity}

## Role of validity

## Discriminatory validity

## Concurrent validity

## Predictive validity


<!--chapter:end:Rmd/07-validity.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

# Outcome {#outcome}

This chapter focusses on the first application of the D-score: the D-score as neurocognitive outcome at 1000 days. In this chapter, we show how the D-score is calculated, demonstrate how to work with the D-score package, and how the D-score can be used as neurocognitive outcome in three different populations. First, the calculations behind the D-score are explained step-by-step and how to do this with the D-score package by means of two example children. Thereafter, the D-scores will be calculated for three different populations at the age of two years: the reference population, population of preterm children, and population of children in LMIC. 


## Application I: D-score as neurocognitive outcome at 1000 days

In the Netherlands, development of children is monitored by using the Dutch Developmental Instrument (DDI; in Dutch: Van Wiechenschema). The DDI consists of 76 items and a subset of these items are assessed at different ages, ranging from 1 month to 4.5 years old. To explain how the D-score is calculated and demonstrate the use of the D-score package two example children, both of the age of 15 months, are used. One of the example children is able to do all items of his/her age, and the other example child is not able to do all items of his/her age. In this way, we can show how different scores on a item affect the D-score.

So for example, for a child of the age of 15 months the Dutch Developmental Instrument consists of the following six items: puts cube in and out of a box, plays 'give and take', crawls (abdomen off the floor), walks along, understands a few words, and says 2 'sound-words' with comprehension. For each of these six items it is noted whether the child was able to perform this item. An example of the results can be found in table \@ref(tab:tableWS), in which *child 1* was able to perform all items and *child 2* was able to perform four of the six items. Based on these scores we can calculate the dscore for both these children.

```{r, echo=FALSE}
child1 <- c(15/12, 1, 1, 1, 1, 1, 1)
child2 <- c(15/12, 1, 0, 1, 1, 1, 0)
tableWS <- rbind(child1, child2)
colnames(tableWS) <- c("age in years", "item 1", "item 2", "item 3", "item 4", "item 5", "item 6")
rownames(tableWS) <- c("child 1", "child 2" )
#item2 : speelt geven/nemen
#item6 : loopt langs
```

```{r, tableWS, echo=FALSE}
library(knitr)
kable(tableWS, caption = "Example of scores on the items of the DDI at the age of 15 months", booktabs = TRUE)
```

Calculation of the D-score is an iterative procedure, in which in each step information of one item is added. The iterative procedure uses Bayes rule to update the prior (knowledge) with data to calculate a posterior. In the next step, this posterior is used as the prior and information, the score, from a new item is added. This results in a new posterior distribution. When the information of all items have been added to the procedure, the D-score is equal to the mean of the final posterior distribution. 

*!!plafond prior nog uitleggen!!*

In the first step, the score of the first item is combined with the prior. However, at the first step we cannot use the previous posterior as our prior. Hence, we need a starting distribution to use as the prior in the first step. It is important that this starting distribution is a bit informative but not too much, so it was decided to choose a quite broad distribution which was centred quite well. The prior was chosen in such a way that the mean value of the prior distribution was equal to the median D-score at that age. The standard deviation is equal to 5, which about twice the normal variation in the D-score.

The starting distributions (priors) for the ages of 1, 15 and 24 months are given in figure \@ref(fig:figpriors). This figure shows that the priors assume that ability of a child of the age of 1 month is lower than the ability of a child of the age of 15 months, which in turn is lower than the ability of a child of the age of 24 months. 

```{r, figpriors, echo = FALSE,  fig.cap="\\label{fig:figpriors} Priors at ages of 1, 15 and 24 months"}
library(dscore)
#example from the adp function in ggplot:
qp <- -10:80

p1m <- data.frame(qp = qp, month = rep(1, length(qp)), p = adp(1/12, qp))
p15m <- data.frame(qp = qp, month = rep(15, length(qp)), p = adp(15/12, qp))
p24m <- data.frame(qp = qp, month = rep(24, length(qp)), p = adp(24/12, qp))

dataprior <- rbind(p1m, p15m, p24m)
dataprior$month <- as.factor(dataprior$month)

p <- ggplot(dataprior, aes(qp, p, group = month)) +
      geom_path(aes(col = month)) +
      coord_cartesian(xlim=c(-10, 80)) +
      scale_y_continuous(name = "Density") +
      scale_x_discrete(name = "D-score")
p
```

First, it is important that the names of the items used are similar to the names of the items in the built-in item bank. In this example the lexicon *gcdg* is used. Moreover, the data should be in long format with the following columnnames: *items*, *scores* and *ages*. This leads to table \@ref(tab:tablenewWS1).

```{r, tablenewWS1, echo=FALSE}
WS1 <- data.frame(child = c("child 1", "child 1", "child 1", "child 1", "child 1", "child 1", "child 2", "child 2", "child 2", "child 2", "child 2", "child 2"),items = c("n32", "n33", "v38", "n37", "n34", "n35", "n32", "n33", "v38", "n37", "n34", "n35"), scores = c(1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0), ages = c(15/12, 15/12, 15/12, 15/12, 15/12, 15/12, 15/12, 15/12, 15/12, 15/12, 15/12, 15/12))

kable(WS1, caption = "Long format of the example of scores on the items of the DDI at the age of 15 months", row.names = NA)
```

Now that the data is in long format and the item names are changed to the lexicon *gcdg*, we can calculate the D-score for both children. In the first step of the iterative procedure, we combine the age-dependent prior of 15 months with the score of the first item *n34* to define the posterior. Item *n34* is a gross motor item: 'crawls, abdomen off the floor'. In table \@ref(tab:tablenewWS1), we can see that both example children were able to crawl with their abdomen off the floor. Note, that we could have chosen any of the items as the first item, since the D-score is independent of the order of items in the calculation. 

The age dependent prior of 15 months and the posterior distribution after adding information from item *n34* are given in figure \@ref(fig:fig1item). In this figure, we can see that the posterior distribution doesnot differ that much from the prior distribution. Both distributions are centred at the same point, while the posterior distribution is smaller than the prior distribution indicating more precision. Since both example children were able to crawl with their abdomen off the floor, the posterior distribution after the first step of the procedure is equal. 

```{r, fig1item, echo=FALSE, fig.cap="\\label{fig:fig1item} Age-dependent priors of 15 months and posterior after 1st item n34"}
items <- c("n34")
age <- 1.25
  
#full posterior 1e item
qp <- -10:80
fp <- dscore(1, items, age, full = TRUE, lexicon = "gcdg", qp = qp)
fp1 <- data.frame(qp = qp, fp = fp[[1]]$posterior, distribution = rep("posterior", length(qp)))
prior <- data.frame(qp = qp, fp = fp[[1]]$start, distribution = rep("prior", length(qp)))

dataprior <- rbind(fp1, prior)
dataprior$distribution <- as.factor(dataprior$distribution)

p1 <- ggplot(dataprior, aes(qp, fp, group = distribution)) +
      geom_path(aes(col = distribution)) +
      coord_cartesian(xlim=c(-10, 80)) +
      scale_y_continuous(name = "Density") +
      scale_x_discrete(name = "D-score")
p1
```

Now, let's add an item on which the scores for the two example children differ, e.g. item *n35*. Item *n35* is also a gross motor item, namely 'walks along'. So both children are able to crawl (with their abdomen of the floor), but only *child 1* is able to walk along. We can use the previously calculated posterior distribution as prior when we add item *n35*. 

Let's start with *child 1*, who is able to walk along. Using Bayes rule, the new posterior distribution can be calculated. In figure \@ref(fig:fig2itemC1) the prior, in this case the posterior after adding item *n34* to the age-dependent prior, and the newly calculated posterior distribution are visualized. Again, the posterior and prior are centred around the same point, while the posterior has a bit more precision.

```{r, fig2itemC1, echo=FALSE, fig.cap="\\label{fig:fig2itemC1} Prior and posterior in the 2nd step of the iterative process for child 1"}
items <- c("n34", "n35")
age <- rep(1.25, length(items))
  
#full posterior 2e item
qp <- -10:80
fp2 <- dscore(c(1,1), items, age, full = TRUE, lexicon = "gcdg", qp = qp)
fp1 <- data.frame(qp = qp, fp = fp[[1]]$posterior, distribution = rep("1st posterior", length(qp)))
fp2 <- data.frame(qp = qp, fp = fp2[[1]]$posterior, distribution = rep("2nd posterior", length(qp)))

datafp <- rbind(fp1, fp2)
datafp$distribution <- as.factor(datafp$distribution)

p2 <- ggplot(datafp, aes(qp, fp, group = distribution)) +
      geom_path(aes(col = distribution)) +
      coord_cartesian(xlim=c(-10, 80)) +
      scale_y_continuous(name = "Density") +
      scale_x_discrete(name = "D-score")
p2


```

Now we can do the same thing for *child 2*, who is able to crawl with his/her abdomen off the floor (*n34*) but not to walk along (*n35*). Again, we can use the posterior after adding information from *n34* as the prior and use the information from *n35* to calculate the posterior. In figure \@ref(fig:fig2itemC2) the prior and posterior are given. Now the prior and posterior are different, the posterior is on the left of the prior and has an high precision in comparison to the prior. Hence, being unable to walk along at the age of 15 months, like *child 2*, is more indicative for the development of a child of 15 months than being able to walk along like *child 1*. 

```{r, fig2itemC2, echo=FALSE, fig.cap="\\label{fig:fig2itemC2} Prior and posterior in the 2nd step of the iterative process for child 2"}
items <- c("n34", "n35")
age <- rep(1.25, length(items))
  
#full posterior 2e item FAIL
qp <- -10:80
fp2 <- dscore(c(1,0), items, age, full = TRUE, lexicon = "gcdg", qp = qp)
fp1 <- data.frame(qp = qp, fp = fp[[1]]$posterior, distribution = rep("1st posterior", length(qp)))
fp2 <- data.frame(qp = qp, fp = fp2[[1]]$posterior, distribution = rep("2nd posterior", length(qp)))

datafp2 <- rbind(fp1, fp2)
datafp2$distribution <- as.factor(datafp2$distribution)

p3 <- ggplot(datafp2, aes(qp, fp, group = distribution)) +
      geom_path(aes(col = distribution)) +
      coord_cartesian(xlim=c(-10, 80)) +
      scale_y_continuous(name = "Density") +
      scale_x_discrete(name = "D-score")
p3

```


The next four steps in the iterative procedure, information from the other four items (*n32*, *n33*, *v38* and *n37*) can be added in a similar fashion. Figure \@ref(fig:fig6itemC1C2) shows the final posterior distributions for *child 1* and *child 2* and the prior distribution for the age of 15 months. The D-score can now be determined by looking at the mean of the posterior distributions. Hence, the D-score for *child 1* and *child 2* are equal to 55.75 and 47.76, respectively.

```{r, fig6itemC1C2, echo=FALSE, fig.cap="\\label{fig:fig6itemC1C2} Prior and final posterior for child 1 and 2"}
items <- c("n32", "n33", "v38", "n37","n34", "n35")
age <- rep(1.25, length(items))
  
#full posterior for both children and prior
qp <- -10:80
fp6_1 <- dscore(c(1,1,1,1,1,1), items, age, full = TRUE, lexicon = "gcdg", qp = qp)
fp6_2 <- dscore(c(1,0,1,1,1,0), items, age, full = TRUE, lexicon = "gcdg", qp = qp)
prior <- data.frame(qp = qp, fp = fp[[1]]$start, distribution = rep("prior", length(qp)))
fp6_1 <- data.frame(qp = qp, fp = fp6_1[[1]]$posterior, distribution = rep("final posterior child 1", length(qp)))
fp6_2 <- data.frame(qp = qp, fp = fp6_2[[1]]$posterior, distribution = rep("final posterior child 2", length(qp)))

datafp6 <- rbind(prior, fp6_1, fp6_2)
datafp6$distribution <- as.factor(datafp6$distribution)

p6 <- ggplot(datafp6, aes(qp, fp, group = distribution)) +
      geom_path(aes(col = distribution)) +
      coord_cartesian(xlim=c(-10, 80)) +
      scale_y_continuous(name = "Density") +
      scale_x_discrete(name = "D-score")
p6

```

```{r, echo=FALSE, message=FALSE}
#Dscore child1
dscore(c(1,1,1,1,1,1), items, age, full = FALSE, lexicon = "gcdg") #55.75
#Dscore child2
dscore(c(1,0,1,1,1,0), items, age, full = FALSE, lexicon = "gcdg") #47.76
```

*nog toe te voegen in de tekst*

*quadratic points*

*Note: met deze methode is het mogelijk om scores voor extremen te berekenen, andere methodes (zoals de worms estimator) kunnen dit niet altijd.*

*Prior die gekozen was: plafond prior (wanneer je alle items kan)*



We already explained how the D-score suffers from a ceiling and bottom at the start and end of the scale. However, this can also happen within the D-score scale: some values of the D-score will never occur no matter the combination of scores on the milestones. This will mainly occur when calibrated milestones are used to calculate the D-score. For example, the Dutch Developmental Instrument (DDI), which is used as a screening instrument, is calibrated: at each wave 90\% of the children should be able to get a positive score on the milestones. Which allows for detection of children with a developmental delay.

During the SMOCC study the milestones of the current wave and the next wave were assessed [@herngreen1994growth]. With the SMOCC dataset we can compare the D-scores calculated by making use of calibrated milestones (the current wave milestones) with the D-scores calculated by making use of non-calibrated milestones (the next wave milestones). These D-scores for children of the age of 2 and 3 months (wave 2 and 3) are plotted against IQ at 5 years in figure \@ref(fig:dscoresnw). The continuous variable IQ at 5 years allows for nice visualization of the variation in D-scores. Moreover, the densities of the D-score are given at the bottom of the plots showing the distribution of the values of the D-score.

```{r, echo=FALSE, message=FALSE, warning = FALSE}
library(gridExtra)
library(dplyr)
data.long <- haven::read_sav("//365tno.sharepoint.com@SSL/DavWWWRoot/teams/P060.33452/TeamDocuments/Team/Work/Booklets/Data/smocc_long3.sav")
data.long$scores_false <- data.long$scores_false - 1
data.long$scores_false_nw <- data.long$scores_false_nw - 1
data.long <- as_tibble(data.long)

data.long$wave <- factor(data.long$wave)
data.long1 <- data.long[!is.na(data.long$IQ), ]
data.long1 <- data.long1[!is.na(data.long1$dscore), ]
data.long1$scores_false <- as.factor(data.long1$scores_false) 
data.long1$scores_false_nw <- as.factor(data.long1$scores_false_nw) 
```

```{r, echo=FALSE, message=FALSE, warning = FALSE}
library(ggplot2)

p2 <- ggplot()+
  geom_point(data=subset(data.long1, wave == c(2)), aes(dscore, IQ, group = wave, col=scores_false), show.legend=F, size = 1)+ 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"))+
  coord_cartesian(xlim=c(0, 75)) +
  scale_y_continuous(name = "IQ at 5 years") +
  scale_x_continuous(name = "D-score (2 month milestones) ") +
  facet_grid(. ~ wave) +
  geom_density(data=subset(data.long1, wave == c(2)),   
               aes(dscore, y = ..density..*100),
               show.legend = F) +
  theme(legend.position = "none") + 
  scale_y_continuous(sec.axis = sec_axis(~./100, name = "Density D-score"))

p3 <- ggplot()+
  geom_point(data=subset(data.long1, wave == c(3)), aes(dscore, IQ, group = wave, col=scores_false), show.legend=F, size = 1)+ 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"))+
  coord_cartesian(xlim=c(0, 75)) +
  scale_y_continuous(name = "IQ at 5 years") +
  scale_x_continuous(name = "D-score (3 month milestones) ") +
  facet_grid(. ~ wave) +
  geom_density(data=subset(data.long1, wave == c(3)),   
               aes(dscore, y = ..density..*100),
               show.legend = F) +
  theme(legend.position = "none") + 
  scale_y_continuous(sec.axis = sec_axis(~./100, name = "Density D-score"))
  

#D-score next wave
p2.nw <- ggplot()+
  geom_point(data=subset(data.long1, wave == c(2)), aes(dscore.nw, IQ, group = wave, col=scores_false_nw), show.legend=F, size = 1)+ 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"))+
  coord_cartesian(xlim=c(0, 75)) +
  scale_y_continuous(name = "IQ at 5 years") +
  scale_x_continuous(name = "D-score (3 month milestones) ") +
  facet_grid(. ~ wave) +
  geom_density(data=subset(data.long1, wave == c(2)),   
               aes(dscore.nw, y = ..density..*100),
               show.legend = F) +
  theme(legend.position = "none") + 
  scale_y_continuous(sec.axis = sec_axis(~./100, name = "Density D-score"))

p3.nw <- ggplot()+
  geom_point(data=subset(data.long1, wave == c(3)), aes(dscore.nw, IQ, group = wave, col=scores_false_nw), show.legend=T, size = 1)+ 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"), 
                      name = "Number of negative scores")+
  coord_cartesian(xlim=c(0, 75)) +
  scale_y_continuous(name = "IQ at 5 years") +
  scale_x_continuous(name = "D-score (6 month milestones) ") +
  facet_grid(. ~ wave) +
  geom_density(data=subset(data.long1, wave == c(3)),   
               aes(dscore.nw, y = ..density..*100),
               show.legend = F) + 
  scale_y_continuous(sec.axis = sec_axis(~./100, name = "Density D-score"))
```

```{r, dscoresnw, echo = FALSE, message=FALSE, warning=FALSE, fig.cap="\\label{fig:dscoresnw} Comparison of the D-scores calculated by calibrated and non-calibrated milestones at the age of 2 months (Wave 2) and 3 months (Wave 3)"}
library(ggpubr)
ggarrange(p2, p2.nw, p3, p3.nw, ncol=2, nrow=2, common.legend = TRUE, legend="bottom")

```

The colours of the dots in figure \@ref(fig:dscoresnw) indicate the number of negative scores on the milestones: note that the number of milestones can differ per wave. Wave 2 has two milestones, Wave 3 has five milestones and Wave 4 has six milestones of the DDI. The variation in the D-score of the children with the same number of negative scores (the same colour of dots) is caused by variation in age. Since the D-score is calculated by using an age-dependent prior, younger children in the same wave with the same scores will have a lower D-score.

Moreover, the plots on the left in figure \@ref(fig:dscoresnw) show that using calibrated milestones leads to a gap between the green dots (zero negative scores) and the yellow dots (one negative score). Since 90\% of the children should be able to get a positive score on each of the milestones implies that the milestones should be quite easy for the children of that age. So, when a child gets a negative score, it should have an impact on the D-score. For example, when a child of the age of 2 months has one negative score, his/her D-score immediately drops from around 20 to around 14. Which implicates that if you use the 2 month milestones for a child of the age of 2 months he/she will never have a D-score in the range of 15 - 18. This shows that it is also possible to have a ceiling/bottom within the D-score scale. This would be ideal in screening purposes, were you want to find children that have a delay in their development in comparison to their peers.

In addition, the plots on the right in figure \@ref(fig:dscoresnw), show the D-scores when non-calibrated milestones (the milestones of the next wave) are used. For the DDI, on average, around 50\% of the children should be able to get a positive score in this situation. For example, 50\% of the children of the age of 2 months should be able to get a positive score on the 3 month milestones. Since these milestones are considered to be more difficult, a negative score on one of the milestones will have a smaller effect on the D-score. Hence, the gap we saw before between the green and yellow dots disappears. Furthermore, there is more variation in the D-scores and the ceiling/bottom within the D-score scale disappears.

Previously described phenomena are also visible in the densities of the D-scores. When the D-scores are calculated with the calibrated milestones, the left plots in figure \@ref(fig:dscoresnw), the density consists (at least) of two (small) peaks. While the D-scores calculated with non-calibrated milestones, the plots on the right, show a broader variation in the values of the D-score. Note, that the density of the D-score in the plot on the bottom right also shows the bottom effect of the D-score: the D-score is at least equal to 20. A lower D-score is not possible with this set of milestones at the age of 3 months. 


```{r, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
#D-scores plot
p.dscore <- ggplot(data.long1, aes(age, dscore, group = wave)) +
  geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"))+
  coord_cartesian(xlim=c(0, 25)) +
  scale_y_continuous(name = "D") +
  scale_x_continuous(name = "age") 
p.dscore

p.dscore.nw <- ggplot(data.long1, aes(age, dscore.nw, group = wave)) +
  geom_point(aes(col=scores_false_nw), show.legend=F, size = 1 )+ 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"))+
  coord_cartesian(xlim=c(0, 25)) +
  scale_y_continuous(name = "D") +
  scale_x_continuous(name = "age") 
p.dscore.nw
```


## D-score of reference children at 2 years (PD)

**Data**

A reference sample was obtained from the Social Medical Survey of Children Attending Child Health Clinics (SMOCC) cohort, a nationally representative cohort of 2,151 children born in The Netherlands during 1988–1989 [@herngreen1994growth]. Of this cohort, general characteristics and developmental milestones of the Dutch Development Instrument at 2y of age (range 22-26 months) were available for 1,583 children.

**Methods**

Several characteristics were selected from the SMOCC cohort.  The following indicators are in agreement with the Global Indicators Project:

- Area of residence:
    - rural: <2,000 inhabitants
    - semi-urban: [2000, 50,000] inhabitants
    - urban: 50,000 – 1 million inhabitants
    - metropolitan: >1 million

-	Number of years of education by the mother (in years)
-	Child related factors:
     - Gestational age (In weeks and in categories of very preterm (<32 weeks), preterm (<37 weeks) and term birth (≥37 weeks))
     - Gender (boys vs girls)
     - Birthweight (in grams)
     - Birth size (in cm)

We also added the following indicators from the SMOCC study:

-	Paternal education (in years)
-	Maternal age (in years)
-	Apgar score after 1 min < 5 (yes vs no)
-	Apgar score after 5 min < 7 (yes vs no)

**Results**

```{r, echo=FALSE}

resultsSMOCC <- data.frame(a = c("Area of Residence","rural", "semi-urban" , "urban", "metropolitan", "Maternal education (in years)", "Paternal education (in years)", "Maternal age (in years)", "Gestational age (in weeks)", "Gestational age (in categories)", "$\\geq 37$ weeks", "$\\geq 32 - 37$ weeks", "$<32$ weeks*", "Gender", "boys", "girls", "Birthweight (in kg)","Birthweight (in categories)", "$\\geq 2500$ grams", "$\\geq 1500 - <2500$ grams", "$<1500$ grams", "Birth size (in cm)", "Apgar score after 1 min", "$<5$", "$\\geq 5$", "Apgar score after 5 min", "$<7$", "$\\geq 7$"),
                b = c(" ","$15$", "$1262$" , "$294$", "$0$", "$1564$", "$1560$", "$1582$", "$1583$", " ", "$1500$", "$78$", "$5$", " ", "$771$", "$812$", "$1583$"," ", "$1490$", "$85$", "$8$", "$1383$", " ", "$29$", "$1306$", " ", "$15$", "$1339$"),
                c = c( " ","$1.0%$", "$80.3%$" , "$18.7%$", "$0.0%$", "$13 (2.3)$", "$14 (2.6)$", "$30 (4.5)$", "$40 (1.8)$", " ", "$94.8%$", "$4.9%$", "$0.3%$", " ", "$51.0%$", "$49.0%$", "$3.419 (0.559)$"," ", "$94.1%$", "$5.4%$", "$0.5%$", "$51 (2.6)$", " ", "$2.2%$", "$97.8%$", " ", "$1.1%$", "$98.9%$"),
                d = c(" ","$0.2838 (0.2467)$", "$0$", "$0.0719 (0.0615)$", " ", "$0.0802 (0.0102)$", "$0.0538 (0.0092)$", "$0.0005 (0.0054)$", "$0.0676 (0.0130)$", " ", "$0$", "$-0.3788 (0.1097)$","$-1.2846 (0.4233)$", " ", "$-0.2904 (0.0473)$", "$0$", "$0.1226 (0.0427)$"," ", "$0$", "$-0.2456 (0.1056)$", "$-0.9539 (0.3358)$", "$0.0165 (0.0097)$", " ", "$0.0524 (0.1752)$", "$0$", " ", "$0.1497 (0.2420)$", "$0$"),
                e = c(" ","$1.15$", " " , "$1.17$", " ", "$7.83$", "$5.83$", "$0.10$", "$5.20$", " ", " ", "$-3.45$", "$-3.03$", " ", "$-6.15$", " ", "$2.87$"," ", " ", "$-2.33$", "$-2.84$", "$1.70$", " ", "$0.3$", " ", " ", "$0.62$", " "),
               f = c(" ","$0.25$", " " , "$0.24$", " ", "$<.001$", "$<.001$", "$0.92$", "$<.001$", " ", " ", "$<.001$", "$0.002$", " ", "$<.001$", " ", "$0.0041$"," ", " ", "$0.0202$", "$0.0046$", "$0.089$", " ", "$0.76$", " ", " ", "$0.54$", " "))

knitr::kable(resultsSMOCC, caption = "Results SMOCC", booktabs = TRUE, digits = 4, col.names = c("Indicators","n","$%$ or mean(SD)", "Model DAZ Coefficient (SE)","Model DAZ t-statistics","Model DAZ p-value"))
```


```{r, echo=FALSE, eval = FALSE}

#Script van Stef:
library("ddata")
library("dscore")
library("dmetric")
studies <- c("Netherlands 1", "Netherlands 2")
data <- get_gcdg(study = studies, min_cat = 10, adm = TRUE, cov = TRUE)
items <- intersect(item_names(study = studies), names(data))
nlbank <- dscore::itembank
d_dutch <- calculate_dscore(data = data, items = items,
                            itembank = nlbank, lexicon = "gcdg")
ref <- dscore::gcdg_reference
d_dutch$daz <- with(d_dutch, dscore::daz(d = d, x = age / 12, ref = ref))
n_items <- data.frame(id = data$id, age = data$age,
                      n = rowSums(!is.na(data[, items])))
d_dutch <- dplyr::left_join(d_dutch, n_items, by = c("id", "age"))
with(d_dutch, (plot(age, d, cex = 0.6)))
with(d_dutch, (plot(age, daz, cex = 0.6)))
write.table(x = d_dutch, file = "notes/dutch_native.txt",
            sep = "\t", na = "", row.names = FALSE, quote = FALSE)

```

## D-score of preterms at 2 years (PD)

**How to adjust development for age of gestation?**

Developmental milestones can be assessed at several chronological ages (defined as age since birth, or postnatal age) to identify very preterm children who have developmental delay and who would benefit from stimulation programs. However, assessment of very preterm children at the same chronological age as term children may cause overdiagnosis of developmental delay in very preterm children and excessive referral for stimulation programs. Very preterm children may require additional time, determined by a factor that considers the difference between gestational age at birth ($GA_{birth}$) vs 40 wk ($GA_{birth}$ for normal term birth), to enable development equivalent to that of normal term birth children. Several authors have proposed full or half correction of chronological age of very preterm birth children to provide a realistic evaluation of age-appropriate milestones; e.g. compare milestones for a child born at $GA_{birth}$ 30 wk vs a normal term child when the chronological age is 10 (full correction, i.e. 40 minus 30 wk) or 5 wk (half correction, i.e. 40 minus 35 wk) lower for the term than very preterm child. The Dutch Development Instrument (DDI) – a modification of the Gesell test – is used in preventive child health care to assess development from birth to chronological age 4 y.

**Data**

In 1983, data were collected for 1338 infants in the Netherlands who had very preterm birth ($GA_{birth} \geq$ 25 and < 32 wk) or very low birth weight (birth weight < 1500 g) (Project On Preterm and Small for Gestational Age Infants [POPS]).

**Methods**

The $GA_{birth}$ was determined from the best obstetric estimate, including last menstrual period, results of pregnancy testing, and ultrasonography findings.
We evaluated development from birth to chronological age 2.5 y in 258 children who had very preterm birth (<32 wk) and no handicaps such as retardation (3 or 4 months retarded or Developmental Quotient between 80 and 90), neurologic disorder, visual or hearing defects, or psychosocial problems. For the calculation of DAZ, the uncorrected and several corrected chronological ages were used according to the equation:

Corrected chronological age ($d$) = uncorrected chronological age ($d$) - ($X_i × 7 × [40 - GA_{birth}(wk)]$)

where the correction factor $X_i$ ranged from full ($X_i = 1$) through half ($X_i = 0.5$) and no correction ($X_i = 0$).
Development was considered equal to the general Dutch population when mean DAZ = 0.

**Results**

Mean DAZ $\pm$ SD for chronological age with correction by $X_i = 1.0$ were:

-	Uncorrected chronological age 19-26 wk: $0.67 \pm 1$;
-	Uncorrected chronological age 32-40 wk: $-0.1 \pm 1$;
-	Uncorrected chronological age 59-66 wk: $-0.1 \pm 1$;
-	Uncorrected chronological age 111-119 wk: $0.1 \pm 1$.

Mean DAZ $\pm$ SD for chronological age with correction by $X_i = 0.75$ was:

-	Uncorrected chronological age 19-26 wk: $-0.1 \pm 1$.

Mean DAZ $\pm$ SD for chronological age with no correction ($X_i = 0$) were:

-	Uncorrected chronological age 19-26 wk: $-1.8 \pm 1$;
-	Uncorrected chronological age 32-40 wk: $-1.9 \pm 1$;
-	Uncorrected chronological age 59-66 wk: $-1.1 \pm 1$;
-	Uncorrected chronological age 111-119 wk: $-0.4 \pm 1$.

**Conclusions**

Compared with the general population, more very preterm children reached developmental milestones within chronological age 26 wk when chronological age was fully corrected, and fewer preterm children reached the milestones when uncorrected chronological age was used; fewer children reached the milestones when 0.5 correction for $GA_{birth}$ was used, and similar proportions were observed when 0.75 correction for $GA_{birth}$ was used within the first 26 weeks after birth. After chronological age 26 wk, similar proportions were observed between very preterm and full term children when chronological age was fully corrected for $GA_{birth}$. We recommend 0.75 correction of chronological age before uncorrected chronological age 26 wk and full correction for uncorrected chronological age 26 to 119 wk.

**Impact of characteristics on the DAZ in preterm children**

**Data**

When we select the DAZ at 2y of fully corrected chronological age (range 22-26 months) within the POPS study, 199 children were available.

**Methods**

Several characteristics were selected from the POPS cohort.  The following indicators are in agreement with the Global Indicators Project:

- Area of residence:
    - rural: <2,000 inhabitants
    - semi-urban: [2000, 50,000] inhabitants
    - urban: 50,000 – 1 million inhabitants
    - metropolitan: >1 million

-	Number of years of education by the mother (in years)
-	Child related factors:
     - Gestational age (In weeks and in categories of very preterm (<32 weeks), preterm (<37 weeks) and term birth (≥37 weeks))
     - Gender (boys vs girls)
     - Birthweight (in grams)
     - Birth size (in cm)

We also added the following indicators from the POPS study:

-	Paternal education (in years)
-	Maternal age (in years)
-	Apgar score after 1 min < 5 (yes vs no)
-	Apgar score after 5 min < 7 (yes vs no)

**Results**

```{r, echo=FALSE}

resultsPOPS<- data.frame(a = c("Area of Residence","rural", "semi-urban" , "urban", "metropolitan", "Maternal education (in years)", "Paternal education (in years)", "Maternal age (in years)", "Gestational age (in weeks)", "Gestational age (in categories)", "$\\geq 37$ weeks", "$\\geq 32 - 37$ weeks", "$<32$ weeks*", "Gender", "boys", "girls", "Birthweight (in kg)","Birthweight (in categories)", "$\\geq 2500$ grams", "$\\geq 1500 - <2500$ grams", "$<1500$ grams", "Birth size (in cm)", "Apgar score after 1 min", "$<5$", "$\\geq 5$", "Apgar score after 5 min", "$<7$", "$\\geq 7$"),
                b = c(" ","$1$", "$120$" , "$71$", "$0$", "$152$", "$156$", "$193$", "$199$", " ", "$0$", "$0$", "$199$", " ", "$88$", "$111$", "$199$"," ", "$1$", "$65$", "$133$", "$165$", " ", "$44$", "$147$", " ", "$16$", "$160$"),
                c = c( " ","$0.5%$", "$62.5%$" , "$37.0%$", "$0%$", "$13.4 (2.2)$", "$14.1 (2.4)$", "$27.5 (4.4)$", "$30.1 (1.4)$", " ", "$0%$", "$0%$", "$100%$", " ", "$44.2%$", "$55.8%$", "$1.371 (0.341)$"," ", "$0.5%$", "$32.7%$", "$66.8%$", "$39.6 (3.2)$", " ", "$77.0%$", "$23.0%$", " ", "$9.1%$", "$90.9%$"),
                d = c(" ","", "$0$", "$-0.1561 (0.1661)$", " ", "$0.07417 (0.03897)$", "$0.08542 (0.03458)$", "$0.01462 (0.01810)$", "$0.02039 (0.05784)$", " ", " ", " "," ", " ", "$-0.09883 (0.15862)$", "$0$", "$0.4280  (0.2299)$"," ", "", "$0.14866 (0.16782)$", "$0$", "$0.01707 (0.02706)$", " ", "$-0.13315 (0.19208)$", "$0$", " ", "$0.56013 (0.28326)$", "$0$"),
                e = c(" "," "," " , "$-0.939$", " ", "$1.903$", "$2.470$", "$0.808$", "$0.352$", " ", " ", " ", " "," ", " ","$0.623$","$1.862$"," "," ","$0.886$"," ","$0.631$", " ", "$-0.693$"," "," ","$1.977$", " "),
               f = c(" "," "," ","$0.349$" , " ","0.0589","$0.0146$","$0.420$","$0.725$", " ", " ", " ", " ", " ", " ", "$0.534$", "$0.0641$", " ", " ","$0.377$", " ", "$0.529$", " ","$0.4890$", " ", " ", "$0.0496$", " "))

knitr::kable(resultsPOPS, caption = "Results POPS", booktabs = TRUE, digits = 4, col.names = c("Indicators","n","$%$ or mean(SD)", "Model DAZ Coefficient (SE)","Model DAZ t-statistics","Model DAZ p-value"))
```


Developmental milestones can be assessed at several chronological ages (defined as age since birth, or postnatal age) to identify very preterm children who have developmental delay and who would benefit from stimulation programs. However, assessment of very preterm children at the same chronological age as term children may cause overdiagnosis of developmental delay in very preterm children and excessive referral for stimulation programs. Very preterm children may require additional time, determined by a factor that considers the difference between gestational age at birth ($GA_{birth}$) vs 40 wk ($GA_{birth}$ for normal term birth), to enable development equivalent to that of normal term birth children. Several authors have proposed full or half correction of chronological age of very preterm birth children to provide a realistic evaluation of age-appropriate milestones; e.g. compare milestones for a child born at $GA_{birth}$ 30 wk vs a normal term child when the chronological age is 10 (full correction, i.e. 40 minus 30 wk) or 5 wk (half correction, i.e. 40 minus 35 wk) lower for the term than very preterm child. The Dutch Development Instrument (DDI) – a modification of the Gesell test – is used in preventive child health care to assess development from birth to chronological age 4 y.


**Purpose**

To investigate the effect of correcting chronological age for $GA_{birth}$ on DDI scores in very preterm infants with no handicaps.


**Methods**

In 1983, data were collected for 1338 infants in the Netherlands who had very preterm birth ($GA_{birth} \geq$ 25 and < 32 wk) or very low birth weight (birth weight < 1500 g) (Project On Preterm and Small for Gestational Age Infants [POPS]). The $GA_{birth}$ was determined from the best obstetric estimate, including last menstrual period, results of pregnancy testing, and ultrasonography findings. We evaluated development from birth to chronological age 2.5 y in 258 children who had very preterm birth and no handicaps such as retardation (3 or 4 months retarded or Developmental Quotient between 80 and 90), neurologic disorder, visual or hearing defects, or psychosocial problems. From birth to chronological age 2.5 y, the DDI included 57 developmental milestones covering 3 domains of child development: fine motor activity, adaptive, and personal/social behavior; communication; and gross motor activity. The DDI was administered by a trained health care professional, and 5 to 9 milestones were evaluated at each health care visit. The child was scored as having passed/reached (was able to perform the milestone at the visit) or failed the milestone (unable to perform). Development score (D-score) was determined from an algorithm that summarized these developmental milestones into a single aggregate score measuring global development. The LMS method was used to transform the D-score to a z-score (DAZ) according to references for development in the Dutch population. For the calculation of DAZ, the uncorrected and several corrected chronological ages were used according to the equation:

Corrected chronological age ($d$) = uncorrected chronological age ($d$) - ($X_i × 7 × [40 - GA_{birth}(wk)]$)

where the correction factor $X_i$ ranged from full ($X_i = 1$) through half ($X_i = 0.5$) and no correction ($X_i = 0$). 
Development was considered equal to the general Dutch population when mean DAZ = 0. Multilevel logistic regression analyses were performed to test the association between $GA_{birth}$ and milestones that were assessed at 2 consecutive visits. 


**Results**

Mean DAZ $\pm$ SD for chronological age with correction by $X_i = 0, 0.5, 0.75$, and $1.0$ were:

-	Uncorrected chronological age 19-26 wk: $-2 \pm 2, -0.7 \pm 1, 0 \pm 1$, and $+0.7 \pm 1$;
-	Uncorrected chronological age 32-40 wk: $-2 \pm 1, -1 \pm 1, -0.5 \pm 1$, and $0 \pm 1$;
-	Uncorrected chronological age 59-66 wk: $-1 \pm 1, -0.6 \pm 1, -0.3 \pm 1$, and $-0.1 \pm 1$;
-	Uncorrected chronological age 111-119 wk: $-0.4 \pm 1, -0.1 \pm 1, 0 \pm 1$, and $0.1 \pm 1$.

In 12 of 18 milestones from all 3 domains, there was a significant positive association between $GA_{birth}$ (25-31 wk) and the proportion of children reaching the milestone after adjustment for uncorrected chronological age. No significant association was observed after adjustment for full correction of chronological age.


**Conclusions**

Compared with the general population, more very preterm children reached developmental milestones within chronological age 26 wk when chronological age was fully corrected, and fewer preterm children reached the milestones when uncorrected chronological age was used; fewer children reached the milestones when 0.5 correction for $GA_{birth}$ was used, and similar proportions were observed when 0.75 correction for $GA_{birth}$ was used within the first 26 weeks after birth. After chronological age 26 wk, similar proportions were observed between very preterm and full term children when chronological age was fully corrected for $GA_{birth}$. We recommend 0.75 correction of chronological age before uncorrected chronological age 26 wk and full correction for uncorrected chronological age 26 to 119 wk.  



## D-score of children in LMIC at 2 years (RO)

## Comparison

<!--chapter:end:Rmd/08-outcome.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Delay {#delay}

## Application II: D-score to identify delayed development (PD)

## Longitudinal D-score patterns in different populations

## Issues in defining developmental delay

## Specificity in reference, pre-term and LMIC populations

## Practical implications

<!--chapter:end:Rmd/09-delay.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ddata)
library(dscore)
library(haven)
library(dplyr)
library(tibble)
library(lme4)
library(MASS)
library(ggplot2)
library(gridExtra)
library(ggpubr)
```

# Consequences {#consequences}

This chapter focusses on the third application of the D-score: the long-term health consequences of delay in development in pre-terms. In this chapter, we explain the relevance of long-term health outcomes and show how the D-score can be used to predict these long-term health outcomes. In addition, we present the practical implications and how this leads to new opportunities and show the impact of early intervention.



## Application III: Long-term health consequences of delay in pre-terms


## Relevance of long-term health outcomes


## Predictive power of D-score

To demonstrate the predictive power of the D-score, we will predict IQ at the age of 5 years for children in the SMOCC dataset. We have data for nine different waves, which includes different numbers of milestones of the Dutch Developmental Instrument (DDI). See table \@ref(tab:tableSMOCC) for an overview.

```{r, echo=FALSE}
w1 <- c(1, 5)
w2 <- c(2, 2)
w3 <- c(3, 5)
w4 <- c(6, 6)
w5 <- c(9, 7)
w6 <- c(12, 6)
w7 <- c(15, 6)
w8 <- c(18, 6)
w9 <- c(24, 6)
tableSMOCC <- rbind(w1, w2, w3, w4, w5, w6, w7, w8, w9)
colnames(tableSMOCC) <- c("Age in months", "Number of milestones of the DDI")
rownames(tableSMOCC) <- c("wave 1", "wave 2", "wave 3", "wave 4",
                          "wave 5", "wave 6", "wave 7", "wave 8",
                          "wave 9")
```

```{r, tableSMOCC, echo=FALSE}
library(knitr)
kable(tableSMOCC, caption = "Overview of the nine waves of the SMOCC data", booktabs = TRUE)
```


First, we will plot the D-scores against IQ at 5 years for each of the waves (see figure \@ref(fig:dscoresIQ5yrs)). In this way, we can see the variation in D-scores for the different waves and how this relates to IQ at the age of 5 years. The colours indicate the number of milestones that got a negative score. Thus, for example, yellow indicates that one of the milestones got a negative score, however this does not mean that all yellow dots in the same plot represent the same number of positive scores. It could be that for some children not all scores of the milestones were available. The same holds, ofcourse, for the other colours as well.

```{r, echo = FALSE}
#Subset van de data zonder de losse scores op de items:
data.long <- haven::read_sav("//365tno.sharepoint.com@SSL/DavWWWRoot/teams/P060.33452/TeamDocuments/Team/Work/Booklets/Data/smocc_long2.sav")
data.long$scores_false <- data.long$scores_false - 1
data.long <- as_tibble(data.long)
data.wide <- haven::read_sav("//365tno.sharepoint.com@SSL/DavWWWRoot/teams/P060.33452/TeamDocuments/Team/Work/Booklets/Data/smocc_wide.sav")
data.wide <- as_tibble(data.wide)


library(gridExtra)
data.long$wave <- factor(data.long$wave)
data.long1 <- data.long[!is.na(data.long$IQ), ]
data.long1 <- data.long1[!is.na(data.long1$dscore), ]
data.long1$scores_false <- as.factor(data.long1$scores_false) 


```




```{r, dscoresIQ5yrs, echo = FALSE,  fig.cap="\\label{fig:dscoresIQ5yrs} The D-scores plotted against IQ at 5 years for each wave", message=FALSE, warning=FALSE}
p1 <- ggplot(subset(data.long1, wave == c(1)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"))+
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p2 <- ggplot(subset(data.long1, wave == c(2)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40"))+
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p3 <- ggplot(subset(data.long1, wave == c(3)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40")) +
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p4 <- ggplot(subset(data.long1, wave == c(4)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40")) +
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p5 <- ggplot(subset(data.long1, wave == c(5)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40")) +
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p6 <- ggplot(subset(data.long1, wave == c(6)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40")) +
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p7 <- ggplot(subset(data.long1, wave == c(7)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40")) +
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p8 <- ggplot(subset(data.long1, wave == c(8)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=T, size = 1 )+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40")) +
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

p9 <- ggplot(subset(data.long1, wave == c(9)), aes(dscore, IQ, group = wave)) +
      geom_point(aes(col=scores_false), show.legend=F, size = 1)+ 
      scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", "2" = "darkorange2", "3" = "red3", "4" = "deeppink3", "5" = "purple3","6" = "steelblue4", "7" = "grey40")) +
      coord_cartesian(xlim=c(0, 75)) +
      scale_y_continuous(name = "IQ at 5 years") +
      scale_x_continuous(name = "D-score") +
      facet_grid(. ~ wave) 

#grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, nrow=3)
library(ggpubr)
ggarrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, ncol=3, nrow=3,
          common.legend = TRUE, legend="bottom")

```
In addition, it is important to note that the number of milestones per wave differ. For example, when we compare the plots for wave 8 and wave 9, it seems that at wave 8 the milestones are more difficult, since there are children who got a negative score on more than one milestone. While at wave 9, the maximum number of milestones with a negative score is one (yellow dots). However, wave 8 contains six milestones of the DDI, while wave 9 only contains one milestone of the DDI. Hence, the difference between the number of milestones at each wave causes the variation in the number of colours used between the nine plots. 

Furthermore, we can see that there is a gap between the cloud of blue dots and the cloud of yellow dots in all nine plots. Or in other words, there is a substantial difference in D-score between children without negative scores and childeren with (at least) one negative score on the milestone(s) of the DDI. The rational behind this, was explained in Chapter 8. 
For most of the waves there is no clear relation between the D-score and IQ at 5 years visible in the plots. However, for wave 7 and 9, we can see that the cloud of blue dots (with higher D-scores) lies a bit higher than the cloud consisting of the other dots. This could indicate that children with an higher D-score at the age of 15 months and 24 months also have an higher IQ at the age of 5 years on average.

Besides the graphical exploration of the relation between the D-score and IQ at 5 years old, we can also use models to determine this relationship. For example, we can model IQ at 5 years old for each wave separately, which allows us to compare the effect of the D-score at each wave on the variation in IQ at 5 years. First, we can estimate models in which the D-score is the only explanatory variable for the variation in IQ at 5 years. The estimate for the D-score and the $R^2$ of these nine models are visualized in figure \@ref(fig:graphestR2).

```{r, echo=FALSE}
# REGRESSION MODELS (per wave)
smocc.wave1 <- subset(data.long, data.long$wave == 1)
smocc.wave2 <- subset(data.long, data.long$wave == 2)
smocc.wave3 <- subset(data.long, data.long$wave == 3)
smocc.wave4 <- subset(data.long, data.long$wave == 4)
smocc.wave5 <- subset(data.long, data.long$wave == 5)
smocc.wave6 <- subset(data.long, data.long$wave == 6)
smocc.wave7 <- subset(data.long, data.long$wave == 7)
smocc.wave8 <- subset(data.long, data.long$wave == 8)
smocc.wave9 <- subset(data.long, data.long$wave == 9)

# Object to save results
results.d <- matrix(c(NA, NA, NA, NA, NA, NA, NA, NA, NA,
                    NA, NA, NA, NA, NA, NA, NA, NA, NA), 
                    nrow = 9, ncol = 2)
colnames(results.d) <- c("Esimate D-score", "$R^2$")
rownames(results.d) <- c("wave 1", "wave 2", "wave 3", "wave 4", "wave 5", "wave 6", "wave 7", "wave 8", "wave 9")

# WAVE 1
mod.wave1 <- lm(IQ ~ dscore, data = smocc.wave1)
results.d[1,1] <- coefficients(mod.wave1)[2]
results.d[1,2] <- summary(mod.wave1)$r.squared 

# WAVE 2
mod.wave2 <- lm(IQ ~ dscore, data = smocc.wave2)
results.d[2,1] <- coefficients(mod.wave2)[2]
results.d[2,2] <- summary(mod.wave2)$r.squared 

# WAVE 3
mod.wave3 <- lm(IQ ~ dscore, data = smocc.wave3)
results.d[3,1] <- coefficients(mod.wave3)[2]
results.d[3,2] <- summary(mod.wave3)$r.squared 

# WAVE 4
mod.wave4 <- lm(IQ ~ dscore, data = smocc.wave4)
results.d[4,1] <- coefficients(mod.wave4)[2]
results.d[4,2] <- summary(mod.wave4)$r.squared 

# WAVE 5
mod.wave5 <- lm(IQ ~ dscore, data = smocc.wave5)
results.d[5,1] <- coefficients(mod.wave5)[2]
results.d[5,2] <- summary(mod.wave5)$r.squared 

# WAVE 6
mod.wave6 <- lm(IQ ~ dscore, data = smocc.wave6)
results.d[6,1] <- coefficients(mod.wave6)[2]
results.d[6,2] <- summary(mod.wave6)$r.squared 

# WAVE 7
mod.wave7 <- lm(IQ ~ dscore, data = smocc.wave7)
results.d[7,1] <- coefficients(mod.wave7)[2]
results.d[7,2] <- summary(mod.wave7)$r.squared 

# WAVE 8
mod.wave8 <- lm(IQ ~ dscore, data = smocc.wave8)
results.d[8,1] <- coefficients(mod.wave8)[2]
results.d[8,2] <- summary(mod.wave8)$r.squared 

# WAVE 9
mod.wave9 <- lm(IQ ~ dscore, data = smocc.wave9)
results.d[9,1] <- coefficients(mod.wave9)[2]
results.d[9,2] <- summary(mod.wave9)$r.squared 


tableIQonlyD <- results.d
```

```{r, tableIQonlyD, echo=FALSE}
#library(knitr)
#kable(tableIQonlyD, caption = "Estimates of the D-score and the $R^2$ for the regression models where only D-score is used as explanatory variable", booktabs = TRUE, digits = 4)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
results.d1 <- as.data.frame(results.d)
names(results.d1) <- c("estimate", "R2")
results.d1$wave <- c(1,2,3,4,5,6,7,8,9)

pest <- ggplot(results.d1, aes(wave, estimate)) +
      geom_point( )+
      scale_y_continuous(breaks = seq(0, 1, 0.2),
                         name = "estimate D-score") +
      scale_x_continuous(breaks = seq(1, 10, 2), name = "Wave") 

pR2 <- ggplot(results.d1, aes(wave, R2)) +
      geom_point( )+
      scale_y_continuous(breaks = seq(0, 0.04, 0.01), 
                         name = "R-squared") +
      scale_x_continuous(breaks = seq(1, 10, 2), name = "Wave") 
```

```{r, graphestR2, echo = FALSE,  fig.cap="\\label{fig:graphestR2} The estimate for the D-score and $R^2$ plotted for each wave", message=FALSE, warning=FALSE}

#arrange
ggarrange(pest, pR2, ncol=2, nrow=1)

```

In figure \@ref(fig:graphestR2), we can see that the estimates for the D-score and the $R^2$ are the highest for wave 7 and wave 9. Indicating that the D-score at wave 7 and wave 9 has the largest effect on IQ at 5 years and explain the most variation in IQ at 5 years. In addition, figure \@ref(fig:graphestR2) shows that the D-score of the first four waves barely explains any variation in IQ at 5 years. Thus, the D-scores of the first six months is not capable of explaining the variation in IQ at 5 years. Hence, the D-score when the children are older is better in explaining the variation in IQ at 5 years. 

Secondly, we can add explanatory variables to the regression model to control for confounding effects. For example, the education level of the mother can also partly explain the variation in IQ at 5 years, so it is important to add these to your prediction model. To predict IQ at 5 years, the following explanatory variables are added to the regression model:

- gender
- birthweight
- birthsize
- agemom: age mother
- edumocat: low, middle or high education level of the mother
- age
- D-score

The first five variables are constant over the waves, while the other two variables vary over time.

For each wave we have estimated two models, *model 1* including all variables as listed above, and *model 2* including all variables except for the D-score. Then, we can compare the explained variation of IQ at 5 years old of both models by comparing the adjusted $R^2$. We have chosen for the adjusted $R^2$ since it corrects for the number of variables added to the model: the $R^2$ will always get higher when a new variable is added to the model. In this way, we can see how much of the variation in IQ is explained by adding the D-score to the regression model for each wave.

```{r, echo=FALSE}

# Object to save results
results <- matrix(c(NA, NA, NA, NA, NA, NA, NA, NA, NA,
                    NA, NA, NA, NA, NA, NA, NA, NA, NA,
                    NA, NA, NA, NA, NA, NA, NA, NA, NA,
                    NA, NA, NA, NA, NA, NA, NA, NA, NA,
                    NA, NA, NA, NA, NA, NA, NA, NA, NA,
                    NA, NA, NA, NA, NA, NA, NA, NA, NA,
                    NA, NA, NA, NA, NA, NA, NA, NA, NA), nrow = 9, ncol = 7)
colnames(results) <- c("Esimate D-score", "95% CI LL", "95% CI UL", "p-value", 
                       "model 1 adj. $R^2$", "model 2 adj. $R^2$", "diff. adj. $R^2$")
rownames(results) <- c("wave 1", "wave 2", "wave 3", "wave 4", "wave 5", "wave 6", 
                       "wave 7", "wave 8", "wave 9")


#In veel waves zijn de haz en waz voor veel kinderen NA.
#Deze wel toevoegen aan het grote model???

# WAVE 1
model.wave1 <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave1)
results[1,1] <- coefficients(model.wave1)[5]
results[1,2] <- confint(model.wave1, level = 0.95)[8, 1]
results[1,3] <- confint(model.wave1, level = 0.95)[8, 2]
results[1,4] <- summary(model.wave1)$coefficients[8,4]  
results[1,5] <- summary(model.wave1)$adj.r.squared 
model.wave1.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize + factor(edumocat) + agemom, data = smocc.wave1)
results[1,6] <- summary(model.wave1.wd)$adj.r.squared 
results[1,7] <- results[1,5] - results[1,6]

# WAVE 2
model.wave2 <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave2)
results[2,1] <- coefficients(model.wave2)[5]
results[2,2] <- confint(model.wave2, level = 0.95)[8, 1]
results[2,3] <- confint(model.wave2, level = 0.95)[8, 2]
results[2,4] <- summary(model.wave2)$coefficients[8,4]  
results[2,5] <- summary(model.wave2)$adj.r.squared
model.wave2.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave2)
results[2,6] <- summary(model.wave2.wd)$adj.r.squared 
results[2,7] <- results[2,5] - results[2,6]

# WAVE 3
model.wave3 <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave3)
results[3,1] <- coefficients(model.wave3)[5]
results[3,2] <- confint(model.wave3, level = 0.95)[8, 1]
results[3,3] <- confint(model.wave3, level = 0.95)[8, 2]
results[3,4] <- summary(model.wave3)$coefficients[8,4]  
results[3,5] <- summary(model.wave3)$adj.r.squared
model.wave3.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave3)
results[3,6] <- summary(model.wave3.wd)$adj.r.squared 
results[3,7] <- results[3,5] - results[3,6]

# WAVE 4
model.wave4 <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave4)
results[4,1] <- coefficients(model.wave4)[5]
results[4,2] <- confint(model.wave4, level = 0.95)[8, 1]
results[4,3] <- confint(model.wave4, level = 0.95)[8, 2]
results[4,4] <- summary(model.wave4)$coefficients[8,4]  
results[4,5] <- summary(model.wave4)$adj.r.squared
model.wave4.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave4)
results[4,6] <- summary(model.wave4.wd)$adj.r.squared 
results[4,7] <- results[4,5] - results[4,6]

# WAVE 5
model.wave5 <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave5)
results[5,1] <- coefficients(model.wave5)[5]
results[5,2] <- confint(model.wave5, level = 0.95)[8, 1]
results[5,3] <- confint(model.wave5, level = 0.95)[8, 2]
results[5,4] <- summary(model.wave5)$coefficients[8,4]  
results[5,5] <- summary(model.wave5)$adj.r.squared
model.wave5.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave5)
results[5,6] <- summary(model.wave5.wd)$adj.r.squared 
results[5,7] <- results[5,5] - results[5,6]

# WAVE 6
model.wave6 <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave6)
results[6,1] <- coefficients(model.wave6)[5]
results[6,2] <- confint(model.wave6, level = 0.95)[8, 1]
results[6,3] <- confint(model.wave6, level = 0.95)[8, 2]
results[6,4] <- summary(model.wave6)$coefficients[8,4]  
results[6,5] <- summary(model.wave6)$adj.r.squared 
model.wave6.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave6)
results[6,6] <- summary(model.wave6.wd)$adj.r.squared 
results[6,7] <- results[6,5] - results[6,6]

# WAVE 7
model.wave7 <- lm(IQ ~ factor(male) + age + birthweight + birthsize + haz + waz
                  + factor(edumocat) + dscore + agemom, data = smocc.wave7)
results[7,1] <- coefficients(model.wave7)[5]
results[7,2] <- confint(model.wave7, level = 0.95)[8, 1]
results[7,3] <- confint(model.wave7, level = 0.95)[8, 2]
results[7,4] <- summary(model.wave7)$coefficients[8,4]  
results[7,5] <- summary(model.wave7)$adj.r.squared
model.wave7.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave7)
results[7,6] <- summary(model.wave7.wd)$adj.r.squared 
results[7,7] <- results[7,5] - results[7,6]

# WAVE 8
model.wave8 <- lm(IQ ~ factor(male) + age+ birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave8)
results[8,1] <- coefficients(model.wave8)[5]
results[8,2] <- confint(model.wave8, level = 0.95)[8, 1]
results[8,3] <- confint(model.wave8, level = 0.95)[8, 2]
results[8,4] <- summary(model.wave8)$coefficients[8,4]  
results[8,5] <- summary(model.wave8)$adj.r.squared
model.wave8.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave8)
results[8,6] <- summary(model.wave8.wd)$adj.r.squared 
results[8,7] <- results[8,5] - results[8,6]

# WAVE 9
model.wave9 <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                  + factor(edumocat) + dscore + agemom, data = smocc.wave9)
results[9,1] <- coefficients(model.wave9)[5]
results[9,2] <- confint(model.wave9, level = 0.95)[8, 1]
results[9,3] <- confint(model.wave9, level = 0.95)[8, 2]
results[9,4] <- summary(model.wave9)$coefficients[8,4]  
results[9,5] <- summary(model.wave9)$adj.r.squared
model.wave9.wd <- lm(IQ ~ factor(male) + age + birthweight + birthsize 
                     + factor(edumocat) + agemom, data = smocc.wave9)
results[9,6] <- summary(model.wave9.wd)$adj.r.squared 
results[9,7] <- results[9,5] - results[9,6]

#Misschien beter om de DAZ er in te doen?!

```

The estimates for the predictor D-score, and it's 95\% confidence interval are given in table \@ref(tab:tableIQ). Moreover, it contains the p-values for the predictor D-score in *model 1* and the adjusted $R^2$'s for *model 1* and *model 2*. The adjusted $R^2$ determines the explained variation in the outcome measure, in this case IQ at 5 years, while penalizing for the number of predictors in the model. Comparison of the $R^2$ is not feasible, since it will always increase when another predictor is added to the model.

```{r, tableIQ, echo=FALSE}
library(knitr)
kable(results, caption = "Comparison of the models per wave to explain IQ at 5 years by D-score", booktabs = TRUE, digits = 4)
```

From table \@ref(tab:tableIQ) we can see that the D-score does not explain variation in IQ at 5 years for the first 6 waves. In other words, the D-scores until the age of 1 year will not explain the variation in IQ at the age of 5 years. However, for wave 7, at the age of 15 months, the estimate for the D-score is just significant and explains almost 3\% of the variation in IQ at the age of 5 years. There is also an almost significant effect of the D-score on IQ at waves 8 and 9, however this only explains around 0.5\% of the variation in IQ at 5 years.

## Practical implications

## Opportunities and impact of early intervention

<!--chapter:end:Rmd/10-consequences.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
# Discussion {#discussion}

## Usefulness of D-score for monitoring child health

## Opportunities for early intervention

## D-score for international settings

## D-score from existing instruments

## Creating new instruments for D-score

<!--chapter:end:Rmd/11-discussion.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Appendix - notation
**!!Eventueel notaties die wij niet gebruikt hebben nog verwijderen uit onderstaande tabel!!**

The notation in this Booklet is based on the notation used in the book of [@wright1982rating].

```{r, echo=FALSE}

tcomb <- data.frame(a = c("MODEL","probability", "" , "", "person", "", "", "", "item step", "", "", "item", "", "", "threshold", "", "",
                          "DATA", "", "", "", "", "", "", "", "", "", "", "", "",
                          "FIT", "", "", "","", "","", "","", "","", "","", "","", "","", "","", ""), 
                b = c("" ,"$\\pi_{nik}$", "$P_{nik}$" , "$P_{rik}$", "$\\beta_n$", "$b_n$", "$b_r$", "$s_n$", "$\\delta_{ij}$", "$d_{ij}$", "$s_{ij}$", "$\\delta_i$", "$d_i$", "$s_i$", "$\\tau_j$", "$h_j$", "$s_j$",
                      "", "$x_{ni}$", "$m_i$", "$m$", "$r_n$", "$T_{ij}$", "$S_{ij}$", "$S_{i+}$", "$S_{+j}$", "$L$", "$M$", "$N$", "$N_r$",
                      "", "$E_{ni}$", "$W_{ni}$", "$C_{ni}$","$y_{ni}$", "$z_{ni}$","$u_i$", "$v_i$","$q_i^2$", "$t_i$","$u_n$", "$v_n$","$q_n^2$", "$t_n$","$G_I$", "$H_I$","$R_I$", "$G_P$","$H_P$", "$R_P$"), 
                c = c("" ,"Model probability of Person $n$ responding in category $k$ to Item $i$", "Estimated probability of Person $n$ responding in category $k$ to Item $i$" , "Estimated probability of a person with test score $r$ responding in categor $k$ to Item $i$", "Ability/attitude of Person $n$", "Estimated ability/attitude of Person $n$", "Estimated ability/attitude of a person with score $r$", "Measurement error", "Difficulty of $j$th step in Item $i$", "Calibration error", "Scale value of item $i$", "Scale value of Item $i$", "Estimated scale value of Item $i$", "Calibration error", "Response threshold $j$", "Estimated response threshold $j$", "Calibration error",
                      "", "Response of Person $n$ to Item $i$", "Number of steps in Item $i$", "Number of thresholds in response format", "Test score of Person $n$", "Number of persons responding in category $j$ of Item $i$", "Number of persons responding in or above category $j$ of Item $i$", "Sample score of Item $i$", "Sample score of catefory $j$", "Number of items", "Number of points on test", "Number of persons", "Number of persons with score $r$",
                      "","Expected value of $x_{ni}$", "Variance of $x_{ni}$", "Kurtosis of $x_{ni}$","Score residual", "Standardized residual","Unweighted mean square for Item $i$", "Weighted mean square for Item $i$","Variance of weighted mean square for Item $i$", "Standardized weighted mean square for Item $i$","Unweighted mean square for Person $n$", "Weighted mean square for Person $n$","Variance of weighted mean square for Person $n$", "Standardized weighted mean square for Person $n$","Item seperation index", "Number of item strata","Sample reliability of item separation", "Person separation index","Number of person strata", "Test reliability of person separation"))


knitr::kable(tcomb, caption = "Notation", booktabs = TRUE, digits = 4, col.names = NULL)
```

```{warnings r}
warnings()
```


<!--chapter:end:Rmd/Appendix-notation.Rmd-->

```{r include=FALSE, cache=FALSE}
# automatically run before each new chapter

# clean out session objects
rm(list = ls(all = TRUE))

# graphical parameter hooks
source("R/hooks.R")
```
`r if (knitr:::is_html_output()) '
# References {-}
'`

<!--chapter:end:Rmd/12-references.Rmd-->

