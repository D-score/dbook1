# Precision {#ch:precision}

The chapter shows the properties of the $D$-score when calculated from
short tests. The study of short tests is useful because it reveals the
behavior of the $D$-score when the measurement is inherently imprecise.

* SMOCC milestone subsets (\@ref(sec:smoccmilestones))

* Comparing two $D$-scores from milestone subsets (\@ref(sec:comparingd))

* Impact of short tests on predicting IQ (\@ref(sec:predictiq))

## SMOCC design: Standard and additional milestones {#sec:smoccmilestones}

At each visit the SMOCC study collected scores on a set of *standard
milestones* (that about 90 percent of the children will pass) and a
set of *additional milestones* (that about 50 percent of the children
will pass). See Section \@ref(sec:smocc).

The SMOCC dataset covers nine different *waves* (occasions, visits).
The set of milestones used in the DDI varies per wave. The number of
standard milestones varies between 2 and 7 at the various waves. The
additional milestones are the standard milestones from the next wave.

```{r smoccfit8, echo = FALSE, warning = FALSE}
library(gseddata)

data <- get_data(cohort = 53)
items <- get_itemnames(data)

varlist <- list(adm = c("cohort", "subjid", "agedays"), 
                items = items,
                cov = NULL)
model <- dmetric::fit_dmodel(varlist, data, name = "57_0")
```

```{r getddi, echo = FALSE}
meta <- dmetric::get_itemtable(get_itemnames(instrument = "ddi")) %>%
  dplyr::select(item, domain, label) %>%
  mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                          "fm" = "Fine motor",
                                          "gm" = "Gross motor")))
df <- data.frame(
  item = get_itemnames(data),
  debut = c(1, 2, 3, 5, 6, 6, 7, 8, 9, 10, 10,
                 4, 7, 8, 9,
                 1, 2, 3, 3, 4, 5, 5, 5, 6, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10, 
                 4, 1, 1, 3, 4, 1, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 8, 8, 9, 10, 9, 9), 
  stringsAsFactors = FALSE)
ddi <- df %>%  
  left_join(meta, by = "item") %>% 
  mutate(
    itemorder = order_itemnames(item, order = "idnm"), 
    debut = factor(debut, 
                   labels = c("1m", "2m", "3m", "6m", "9m", "12m", "15m", "18m", "24m", "30m"))
    ) %>% 
  arrange(debut, itemorder) %>% 
  dplyr::select(item, debut, domain, label)

# data <- get_data(cohort = 53)
# ddi <- data$itm %>%
#   group_by(item) %>% 
#   summarize(min_age = min(agedays, na.rm = TRUE)) %>% 
#   mutate(visit = cut(min_age, 
#                     breaks = c(18, 43, 76, 149, 216, 320, 399, 481, 633, 800),
#                     labels = c("1m", "2m", "3m", "6m", "9m", "12m", "15m", "18m", "24m"),
#                     right = FALSE),
#          wave = as.integer(visit)) %>% 
#   arrange(wave) %>% 
#   dplyr::select(wave, visit, item)
```

```{r tableSMOCC, echo=FALSE}
tableSMOCC <- data.frame(
  Age = names(table(ddi$debut)),
  Standard = as.vector(table(ddi$debut)),
  Additional = c(as.vector(table(ddi$debut))[-1], 0), 
  stringsAsFactors = FALSE)
tableSMOCC <- tableSMOCC[-nrow(tableSMOCC), ]
kable(tableSMOCC, 
      caption = "Overview of the nine waves of the SMOCC data", 
      booktabs = TRUE)
```

Table \@ref(tab:tableSMOCC) summarizes the schedules age for each
wave, the number of standard milestones and the number of additional
milestones.

```{r ageitemgrid, echo=FALSE, fig.height = 10, fig.cap='(ref:ageitemgrid)'}
# split response into standard/additional according to 
# item-agedays combinations

data2 <- left_join(data$itm, ddi, by = "item") %>%
  tidyr::drop_na(agedays) %>% 
  mutate(itemorder = order_itemnames(item, order = "idnm")) %>% 
  arrange(desc(debut), desc(itemorder)) %>% 
  mutate(ord = 1:n(), 
         agemos = agedays / 365.25 * 12, 
         visit  = cut(agedays, 
                    breaks = c(18, 43, 76, 149, 216, 320, 399, 481, 633, 1200),
                    labels = c("1m", "2m", "3m", "6m", "9m", "12m", "15m", "18m", "24m"),
                    right = FALSE))

g <- ggplot(data2, aes(y = agemos, x = reorder(item, ord), color = debut)) +
  coord_flip() +
  geom_point(size = 0.7) +
  scale_y_continuous(breaks = seq(0, 30, 6)) +
  ylab("Age (months)") +
  labs(color = "Debut") +
  theme_light() +
  theme(panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_line(),
        axis.text.y = element_text(family = "Courier", face = "bold"),
        axis.title.y = element_blank(), 
        legend.position = c(0.85, 0.75))
g
```

(ref:ageitemgrid) Age-item grid of the SMOCC study, illustrating how
the 57 DDI items are distributed over nine visits during the first 24
months.

Figure \@ref(fig:ageitemgrid) shows which subset of DDI items is
administered at each age. For example, at the 1-month visit the five
standard milestones are `ddicmm029 - ddigm056` and the two additional
milestones are `ddicmm030` and `ddifmd002`. At the 2-month visit, the
standard milestones are `ddicmm030` and `ddifmd002`, and the five
additional milestones are `ddicmm031 - ddigmd057`. And so on.

## $D$-score from short tests {#sec:comparingd}

### Milestone sets

In the analyses done thus far we have calculated $D$-scores from
responses on the combined (standard plus additional) milestones. Thus,
at the 2-month visit, the $D$-score was calculated from 2 (standard) +
5 (additional) = 7 milestones.

In daily practice, the set of additional milestones is often lacking.
This chapter explores the impact of using the (smaller) subset of
standard milestones on measurement error and prediction.

This section reports and compares three $D$-scores: 

1. $D$-score from standard milestones;
2. $D$-score from additional milestones.
3. $D$-score from all available milestones;

Estimation of 1 is more difficult than for 2 and 3, for the following
reasons:

* There are fewer milestones, so the estimate is less precise and more
influenced by the choice of the prior distribution;

* The standard set contains only easy milestones, which are
uninformative for the majority of children.

### Milestone sets at month 2

```{r d3, echo = FALSE}
# calculate three versions of D-score

# calculate std set of items
data3 <- data2 %>% 
  mutate(visit_n = as.integer(visit),
         debut_n = as.integer(debut), 
         std = visit_n >= debut_n, 
         exact = visit_n == debut_n, 
         age = round(agedays / 365.25, 4)) %>% 
  dplyr::select(subjid, agedays, age, item, value, std, exact)

# split three versions of the data
data_std <- data3 %>% 
  dplyr::filter(exact) %>%
  dplyr::select(-std) %>% 
  tidyr::spread(key = "item", value = "value")
data_add <- data3 %>% 
  dplyr::filter(!std) %>%
  dplyr::select(-exact) %>% 
  tidyr::spread(key = "item", value = "value")
data_all <- data3 %>% 
  dplyr::select(-std, -exact) %>% 
  tidyr::spread(key = "item", value = "value")

# determine dscore key
dkey <- data.frame(item = model$itembank[, paste("lex", "gsed", sep = "_")],
                   delta = model$itembank$tau,
                   stringsAsFactors = FALSE)

# calculate the ability for three versions
beta_std <- dscore::ability(data = data_std, 
                            items = intersect(items, names(data_std)), 
                            key = dkey)
beta_add <- dscore::ability(data = data_add, 
                            items = intersect(items, names(data_add)), 
                            key = dkey)
beta_all <- dscore::ability(data = data_all, 
                            items = items, 
                            key = dkey)

# combine into one data set
data_std <- cbind(data_std[, c("subjid", "agedays")], 
                  d_std = beta_std$b, n_std = beta_std$n, 
                  s_std = rowSums(data_std[, -(1:4)], na.rm = TRUE),
                  f_std = rowSums(1 - data_std[, -(1:4)], na.rm = TRUE))
data_add <- cbind(data_add[, c("subjid", "agedays")], 
                  d_add = beta_add$b, n_add = beta_add$n,
                  s_add = rowSums(data_add[, -(1:4)], na.rm = TRUE),
                  f_add = rowSums(1 - data_add[, -(1:4)], na.rm = TRUE))
data_all <- cbind(data_all[, c("subjid", "agedays")], 
                  d_all = beta_all$b, n_all = beta_all$n,
                  s_all = rowSums(data_all[, -(1:4)], na.rm = TRUE),
                  f_all = rowSums(1 - data_all[, -(1:4)], na.rm = TRUE))
broad <- data$visit %>% 
  left_join(data_all, by = c("subjid", "agedays")) %>% 
  left_join(data_std, by = c("subjid", "agedays")) %>% 
  left_join(data_add, by = c("subjid", "agedays"))
```

```{r preparmonth2d, echo = FALSE, message=FALSE, warning=FALSE}
long1 <- broad %>% 
  dplyr::select(subjid, agedays, d_all, d_std, d_add) %>% 
  tidyr::gather(d_all:d_add, key = "set", value = "d") %>% 
  mutate(set = substr(set, 3, 5), 
         set = factor(set, levels = c("std", "add", "all"), 
                      labels = c("Standard", "Additional", "All")), 
         agemos = round(agedays / 365.25 * 12, 3),
         visit  = cut(agedays, 
                      breaks = c(18, 43, 76, 149, 216, 320, 399, 481, 633, 1200),
                      labels = c("1m", "2m", "3m", "6m", "9m", "12m", "15m", "18m", "24m"),
                      right = FALSE))
long2 <- broad %>% 
  dplyr::select(subjid, agedays, n_all, n_std, n_add) %>% 
  tidyr::gather(n_all:n_add, key = "set", value = "n")
long3 <- broad %>% 
  dplyr::select(subjid, agedays, s_all, s_std, s_add) %>% 
  tidyr::gather(s_all:s_add, key = "set", value = "s")
long4 <- broad %>% 
  dplyr::select(subjid, agedays, f_all, f_std, f_add) %>% 
  tidyr::gather(f_all:f_add, key = "set", value = "f")
long <- bind_cols(long1, n = long2$n, pass = long3$s, fail = long4$f)
```

```{r month2d, echo = FALSE, message=FALSE, warning=FALSE, fig.height = 4, fig.cap='(ref:month2d)'}
g <- ggplot(subset(long, 
                   subset = (set == "Standard" & visit == "2m" & n == 2) | 
                     (set == "Additional" & visit == "2m" & n == 5) |
                     (set == "All" & visit == "2m")), 
            aes(x = agemos, y = d, col = as.factor(fail))) +
  geom_point() + 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", 
                                 "2" = "darkorange2", "3" = "red3", 
                                 "4" = "deeppink3", "5" = "purple3",
                                 "6" = "steelblue4", "7" = "grey40")) +
  xlab("Age (in months)") +
  ylab("D-score") +
  labs(col = "Fails") +
  facet_wrap("set") +
  ylim(4, 35) +
  guides(col = guide_legend(nrow = 1)) +
  theme_light() +
  theme(legend.position = "bottom")
g  
```

(ref:month2d) Distribution of the $D$-scores calculated from the
standard, additional and all available milestones at month 2. Colors
correspond to the number of fails.

The vertical axis of Figure \@ref(fig:month2d) shows the $D$-score,
separately calculated from the standard, additional and all available
milestones for children aged 2 months. The color of the dots
represents the number of FAIL scores within each set of milestones.

At month 2 there are just two standard milestones: `ddicmm030` and
`ddifmd002`. About 90 percent of the infants will pass these. The
estimated $D$-scores corresponding to two passes is represented by the
green dots in the left-hand side figure. As explained in Section
\@ref(sec:adp), the $D$-score is calculated by using an age-dependent
prior. If the ages vary (and they do), then the $D$-score for infants
having the same total score will also vary. 

If a child fails on either `ddicmm030` or `ddifmd002`, then the
$D$-score is substantially lower. The left-hand figure shows a *gap*
between the green dots (perfect score) and the yellow dots (one FAIL).
The impact of a FAIL on the $D$-score is substantial. For example, the
$D$-score of an infant with one FAIL on a standard milestone drops
from about 20$D$ to 14$D$. Thus, with these two milestones there
cannot be a $D$-score in the range 15$D$ - 18$D$. It depends on the
purposes of the measurement whether this is acceptable. We can prevent
such gaps by measuring more milestones, e.g., milestones taken from
the additional set. Another gap occurs between 14$D$ and 11$D$. These
gaps illustrate that precision is constrained when only two milestones
are administered.

The middle figure shows the estimated $D$-score at the same visit, but
now calculated from the five additional milestones (i.e., the standard
milestones from month 3). Infant aged 2 months have approximately a 50
percent chance of passing each. Note that administration of the additional milestones 
will cover the range 14$D$-20$D$ quite well. Note the ceiling is also 
higher with these milestones. 

Note that the range of the estimated $D$-scores is quite similar in
both plots. This is because $D$-score estimation takes the difficulty
level of milestones into account. The estimate of the $D$-score is
*unbiased* for difficulty.

### Milestone sets at month 3

```{r month3d, echo = FALSE, message=FALSE, warning=FALSE, fig.height = 4, fig.cap='(ref:month3d)'}
g <- ggplot(subset(long, 
                   subset = (set == "Standard" & visit == "3m" & n == 5) | 
                     (set == "Additional" & visit == "3m" & n == 6) |
                     (set == "All" & visit == "3m")), 
            aes(x = agemos, y = d, col = as.factor(fail))) +
  geom_point() + 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", 
                                 "2" = "darkorange2", "3" = "red3", 
                                 "4" = "deeppink3", "5" = "purple3",
                                 "6" = "steelblue4", "7" = "grey40",
                                 "8" = "grey20", "9" = "grey10")) +
  xlab("Age (in months)") +
  ylab("D-score") +
  labs(col = "Fails") +
  facet_wrap("set") +
  ylim(4, 35) +
  guides(col = guide_legend(nrow = 1)) +
  theme_light() +
  theme(legend.position = "bottom")
g  
```

(ref:month3d) Distribution of the $D$-scores calculated from the
standard, additional and all available milestones at month 3. Colors
correspond to the number of fails.

Figure \@ref(fig:month3d) is the same plot as before, but now for
month 3. Compared to Figure \@ref(fig:month2d) all points shifted
upwards, as a consequence that the children are now one month older.

The additional milestones from month 2 are the standard milestones of
month 3. In Figure \@ref(fig:month2d) there were at least 11 children
(in purple) failed all five additional milestones. One month later,
there is one child having five fails.

### Floor and ceiling effects

```{r alld, echo = FALSE, message=FALSE, warning=FALSE, fig.height = 4, fig.cap='(ref:alld)'}
g <- ggplot(drop_na(long, fail), 
            aes(x = agemos, y = d, col = as.factor(fail))) +
  geom_point(size = 0.6, shape = 16) + 
  scale_colour_manual(values = c("0" = "springgreen3", "1" = "gold2", 
                                 "2" = "darkorange2", "3" = "red3", 
                                 "4" = "deeppink3", "5" = "purple3",
                                 "6" = "steelblue4", "7" = "grey40",
                                 "8" = "grey20", "9" = "grey10", 
                                 "10" = "black", "11" = "black", 
                                 "12" = "black", "13" = "black", 
                                 `NA` = "grey")) +
  ylab("D-score") +
  labs(col = "Fails") +
  facet_wrap("set") +
  guides(col = guide_legend(nrow = 1)) +
  theme_light() +
  scale_x_continuous(name = "Age (in months)", 
                     breaks = seq(0, 30, 6), 
                     limits = c(0, 30)) +
  theme(legend.position = "bottom")
g  
```

(ref:alld) $D$-score by age 0-30 months for standard, additional and
all available milestones at each measurement occasion.

Figure \@ref(fig:alld) plot the $D$-score distribution for all
occasions. Some observations:

* *Ceiling effect*: The ceiling effect (green) is most prominent in
the *standard* set, but is also present in the other two sets. None of
the three sets is able to filter out children with really advanced
development. In order to achieve more precision at the upper end, we
would need to include more difficult milestones.

* *Floor effect*: There are almost no floor effects in the *standard*
and *all* sets. These sets discriminate well among children with
delayed development, which was the design purpose of the DDI. Floor
effects visible in the *additional* set.

* *Average level*: All three sets capture the overall relation between
age and development. The *additional* set is quite efficient for
measuring average levels development, but lacks detail on the
extremes.

Figure \@ref(fig:alld) shows that a short test (5-6 milestones) can
precisely measure the lower tail of the $D$-score distribution
(*standard* set) or the middle of the $D$-score distribution
(*additional* set), but cannot do both at the same time.

## Impact of short tests on predicting IQ {#sec:predictiq}

### Measurement and prediction

In Section \@ref(sec:comparingd) we saw that a short test can measure
the middle or one tail of the distribution, but cannot be precise for
both at the same time. If we want to identify children at risk for
delayed development, we are interested in the lower tail of the
distribution, so in that case the *standard* set is suitable. But what
set should we use if we want to predict a later outcome?

This section explores that effect of taking different milestone sets
on the quality of prediction.

### UKKI

@hafkamp2009 studied the effect of the $D$-score on later intelligence, 
using a subset of 557 SMOCC children that were followed up at the age
of five years. 

Intelligence was measured by the Utrechtse Korte Kleuter
Intelligentietest (UKKI) [@baarda1978]. The UKKI is a simple test with
just three components:

* Redraw five figures (square, triangle, cross, trapezoid, rhomboid);

* Draw human figure, with 28 characteristics, like legs, eyes, and so on;

* Give meaning to 13 words like knife, banana, umbrella, and so on.

Administration time is about 15-20 minutes. The UKKI has a reasonable
test-retest reliability for group use (Pearson $r = 0.74$, 3-month
interval).

### Exploratory analysis

```{r echo = FALSE}
# Obtain IQ scores
ids <- data$visit %>% 
  dplyr::select(subjid, subjido) %>% 
  group_by(subjid) %>% 
  slice(1) %>% 
  ungroup()
data_iq <- haven::read_sav("data-raw/data/smocc/SMOCC 5 years BMGF.sav") %>% 
  dplyr::select(pnr, iq) %>% 
  rename(IQ = iq) %>% 
  mutate(subjido = as.character(pnr)) %>%
  left_join(ids, by = "subjido") %>% 
  dplyr::select(-pnr, -subjido) %>% 
  drop_na(IQ)
```

```{r histiq, echo = FALSE, message=FALSE, warning=FALSE, fig.height = 4, fig.cap='(ref:histiq)'}
g <- ggplot(data_iq, aes(x = IQ)) + 
  theme_light() +
  geom_histogram(binwidth = 5, fill = "#006CC2B3", colour = "white") +
  scale_x_continuous(breaks = seq(50, 150, 10)) +
  ylab("Frequency")
g
```

(ref:histiq) Histogram of UKKI *IQ* scores taken around the age of
five years (SMOCC data, $n = 557$).

Figure \@ref(fig:histiq) shows the empirical IQ distribution of 557
children. The mean IQ score is 108 and the standard deviation is 15,
so the IQ-scores of children in the sample is about a half standard
deviation above the 1978 reference sample. 

```{r plotdiq, echo = FALSE, message=FALSE, warning=FALSE, fig.height = 16, fig.cap='(ref:plotdiq)'}
long2 <- long %>%
  left_join(data_iq, by = "subjid") %>% 
  drop_na(IQ, visit)

g <- ggplot(long2, aes(x = d, y = IQ)) +
  geom_point(size = 0.6, shape = 16, color = "grey80") + 
  xlab("D-score") +
  facet_grid(rows = vars(visit), cols = vars(set)) +
  stat_smooth(method = lm, se = FALSE, span = 2, col = "red") +
  theme_light() +
  theme(legend.position = "none")
g  
```

(ref:plotdiq) Relation between $D$-score at infancy and *IQ* at age 5
according to three milestone sets and nine visit (SMOCC data, $n = 557$).

```{r reg2, echo = FALSE, results = 'hide'}
summary(lm(IQ ~ d, data = long2, subset = visit == "24m" & set == "Standard"))
summary(lm(IQ ~ d, data = long2, subset = visit == "24m" & set == "Additional"))
summary(lm(IQ ~ d, data = long2, subset = visit == "24m" & set == "All"))
```


Figure \@ref(fig:plotdiq) shows that the relation between the
$D$-score 0-2 years and IQ at 5 years is positive for all milestone
sets and for all ages. The strength of the relation increases with
age. At the age of 2 years, the regression coefficient for $D$-score
is equal to $\beta(D) = 1.4$ (SE: $0.21, p < 0.0001$), so on average
an increase of 1.0 unit in the $D$-score at the age of 2 years
corresponds to a 1.4 IQ-score points increase at the age 5 years.

```{r cordiq, echo = FALSE}
cors <- long2 %>% 
  group_by(set, visit) %>% 
  summarise(cr = cor(d, IQ, use = "pairwise")) %>% 
  spread(set, cr)
kable(cors, 
      col.names = c("Visit", "Standard set", "Additional set", "All milestones"),
      caption = "Pearson correlation between D-score (0-2 years) and IQ at 5 years", 
      booktabs = TRUE, digits = 3)
```

Table \@ref(tab:cordiq) summarizes the Pearson correlations between
the $D$-score and later IQ. The association between $D$-score and IQ
is weak during the first year of life, but gets stronger during the
second year. In general, having more (and more informative) milestones
helps to increase the correlation, but the effect are relatively
small. So even from the standard set of the seven easy milestones at
24m we obtain a reasonable correlation of 0.245. 

All in all, these results suggest that neither the amount nor the
difficulty level of the milestones are critical in determining the
strength of the relation between the $D$-score and IQ.
