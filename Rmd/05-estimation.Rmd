# Computation {#ch:computation}

> Author: Stef van Buuren

This chapter explains the basic computations needed for fitting and evaluating the Rasch model. We distinguish the following steps:

* Identify nature of the problem (\@ref(sec:datapreparation))
* Estimation of item parameters (\@ref(sec:itemestimation))
* Anchoring (\@ref(sec:anchoring))
* Estimation of the $D$-score (\@ref(sec:dscoreestimation))
* Estimation of age-conditional references (\@ref(sec:reference))

Readers not interested in these details may continue to model evaluation in Chapter \@ref(ch:evaluation).

## Identify nature of the problem {#sec:datapreparation}

The SMOCC dataset, introduced in Section \@ref(sec:smocc), contains scores on the DDI of Dutch children aged 0-2 years made during nine visits.

```{r smoccmodel5, dependson = "smoccmodel", cache = FALSE}
data <- knitr::load_cache("smoccmodel", "data")
items <- knitr::load_cache("smoccmodel", "items")
model <- knitr::load_cache("smoccmodel", "model")
```

```{r smocctable, warning = FALSE}
broad <- as.data.frame(data) %>% 
  dplyr::select(subjid, agedays, all_of(items)) %>% 
  dplyr::slice(1:26)
options(knitr.table.format = "html", knitr.kable.NA = "") 
kable(broad,
      caption = "SMOCC DDI milestones, first three children, 0-2 years.",
      row.names = FALSE, 
      col.names = c("Child", "Age (days)", substr(items, 8, 9))) %>%
  kableExtra::kable_styling(full_width = TRUE) %>%
  kableExtra::column_spec(3:59, width_max = "3em") %>%
  kableExtra::scroll_box(width = "100%", height = "300px")
```
&nbsp;

Table \@ref(tab:smocctable) contains data of three children, measured on nine visits between ages 0 - 2 years. The DDI scores take values 0 (FAIL) and 1 (PASS). In order to save horizontal space, we truncated the column headers to the last two digits of the item names.

Since the selection of milestones depends on age, the dataset contains a large number of empty cells. Naive use of sum scores as a proxy to ability is therefore problematic. An empty cell is not a FAIL, so it is incorrect to impute those cells by zeroes.

Note that some rows contain only 1's, e.g., in row 2. Many computer programs for Rasch analysis routinely remove such *perfect scores* before fitting. However, unless the number of perfect scores is very small, this is not recommended because doing so can severely affect the ability distribution.

In order to effectively handle the missing data and to preserve all persons in the analysis we separate estimation of item difficulties (c.f. section \@ref(sec:itemestimation)) and person abilities (c.f. section \@ref(sec:dscoreestimation)).

## Item parameter estimation {#sec:itemestimation}

### Pairwise estimation of item difficulties

There are many methods for estimating the difficulty parameters of the Rasch estimation. See @linacre2004 for an overview.

We will use the pairwise estimation method. This method writes the probability that child $n$ passes item $i$ but not item $j$ given that the child passed one of them as $\exp(\delta_i) / (\exp(\delta_i) + \exp(\delta_j))$. The method optimizes the pseudo-likelihood of all item pairs over the difficulty estimates by a simple iterative procedure.

@zwinderman1995 has shown that this procedure provides consistent estimates with similar efficiency computationally more-intensive conditional and marginal maximum likelihood methods.

The beauty of the method is that it is independent of the ability distribution, so there is no need to remove perfect scores. We use the function `rasch.pairwise.itemcluster()` as implemented in the `sirt` package [@robitzsch2016].

```{r itemdiflplot, fig.height = 10, fig.cap = '(ref:itemdiflplot)'}
d1 <- data.frame(delta = model$fit$b, 
                 item = names(model$fit$b), 
                 stringsAsFactors = FALSE, 
                 row.names = NULL)
ib <- model$itembank %>% 
  left_join(d1, by = "item") %>% 
  mutate(lab = substr(label, 1L, 30)) %>% 
  mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                          "fm" = "Fine motor",
                                          "gm" = "Gross motor")))

p <- ggplot(ib, aes(x = delta, y = reorder(lab, -delta))) + 
  geom_segment(aes(yend = lab), xend = -30, colour = "grey50") +
  geom_point(size = 2, aes(colour = domain)) + 
  theme(panel.grid.major.y = element_blank()) +
  facet_grid(domain ~ ., scales = "free_y", space = "free_y") + 
  theme(legend.position = "none") + 
  xlab("Item difficulty (logits)") +
  theme(axis.title.y = element_blank())
p
```
(ref:itemdiflplot) Estimated item difficulty parameters ($d_i$) for 57 milestones of the DDI (0 - 2 years).

Figure \@ref(fig:itemdiflplot) summarizes the estimated item difficulty parameters. Although the model makes no distinction between domains, the results have been ordered to ease spotting of the natural progression of the milestones per domain. The figure also suggests that not all domain have equal representation across the scale. For example, there are no communication milestones around the logit of $-10$.

### Anchoring {#sec:anchoring}

The Rasch model identifies the item difficulties up to a linear transformation. By default, the software produces estimates in the logit scale (c.f. Figure \@ref(fig:itemdiflplot)). The logit scale is inconvenient for two reasons:

* The logit scale has negative values. Negative values do not have a sensible interpretation in child development, and are likely to introduce errors in practice;

* Both the zero in the logit scale, as well as its variance, depend on the sample used to calibrate the item difficulties.

Rescaling preserves the properties of the Rasch model. To make the scale independent of the specified sample, we transform the scale so that two items will always have the same value on the transformed scale. The choice of the two anchor items is essentially arbitrary, but they should correspond to milestones that are easy to measure with small error. In the sequel, we use the two milestones to anchor the $D$-score scale:

```{r anchor}
df <- data.frame(
  Item = c("ddigmd057", "ddigmd063"),
  Label = c("Lifts head to 45 degrees on prone position", 
            "Sits in stable position without support"),
  Value = c(20, 40), 
  stringsAsFactors = FALSE)
kable(df, 
      caption = "Anchoring values used to identify the $D$-score scale", 
      booktabs = TRUE)
```
&nbsp;

With the choice of Table \@ref(tab:anchor), $D$-score values are approximately 0$D$ around birth. At the age of 1 year, the score will around 50$D$, so during the first year of life, one $D$ unit corresponds to approximately a one-week interval.

```{r itemdifdplot, fig.height = 10, fig.cap = '(ref:itemdifdplot)'}
p <- ggplot(ib, aes(x = tau, y = reorder(lab, -delta))) + 
  geom_segment(aes(yend = lab), xend = -30, colour = "grey50") +
  geom_point(size = 2, aes(colour = domain)) + 
  theme(panel.grid.major.y = element_blank()) +
  facet_grid(domain ~ ., scales = "free_y", space = "free_y") + 
  theme(legend.position = "none") + 
  xlab("Item difficulty (D-score)") +
  theme(axis.title.y = element_blank())
p
```
(ref:itemdifdplot) Estimated item difficulty parameters ($d_i$) for 57 milestones of the DDI (0 - 2 years). Milestones `ddigmd057` and `ddigmd063` are anchored at values of 20$D$ and 40$D$, respectively.

## Estimation of the $D$-score {#sec:dscoreestimation}

The second part of the estimation process is to estimate a $D$-score. The $D$-score quantifies the development of a child at a given age. Whereas the instrument developer is responsible for the estimation of item parameters, $D$-score estimation is more of a task for the user. To calculate the $D$-score, we need the following ingredients:

* Child's PASS/FAIL scores on the milestones administered;

* The difficulty estimates of each milestone administered;

* A prior distribution, an estimate of the $D$-score distribution before seeing any PASS/FAIL score.

Using these inputs, we may use Bayes theorem to calculate the position of the person on the latent variable.

### Role of the starting prior {#sec:startingprior}

The first two inputs to the $D$-score will be self-evident. The third component, the prior distribution, is needed to be able to deal with perfect responses. The prior distribution summarizes our knowledge about the $D$-score before we see any of the child's PASS/FAIL scores. In general, we like the prior to be non-informative, so that the observed responses and item difficulties entirely determine the value of the $D$-score. In practice, we cannot use truly non-informative prior because that would leave the $D$-score for perfect responses (i.e., all PASS or all FAIL) undefined. The choice of the prior is essentially arbitrary, but we can make it in such a way that its impact on the value $D$-score is negligible, especially for tests where we have more than, say, four items.

Since we know that the $D$-score depends on age, a logical choice for the prior is to make it dependent on age. In particular, we will define the prior as a normal distribution equal to the expected mean in Figure \@ref(fig:smoccda) at the child's age, and with a standard deviation that considerably higher than in Figure \@ref(fig:smoccda). Numerical example: the mean $D$-score at the age of 15 months is equal to 53.6$D$. The standard deviation in Figure \@ref(fig:smoccda) varies between 2.6$D$ and 3.0$D$, with an average of 2.9$D$. After some experimentation, we found that using a value of 5.0$D$ for the prior yields a good compromise between non-informativeness and robustness of $D$-score estimates for perfect patterns. The resulting starting prior for a child aged 15 months is thus $N(53.6, 5)$.

The reader now probably wonders about a chicken-and-egg problem: To calculate the $D$-score, we need a prior, and to determine the prior we need the $D$-score. So how did we calculate the $D$-scores in Figure \@ref(fig:smoccda)? The answer is that we first took at rougher prior, and calculated two temporary models in succession using the $D$-scores obtained after solution 1 to inform the prior before solution 2, and so on. It turned out that $D$-scores in Figure \@ref(fig:smoccda) hardly changed after two steps, and so there we stopped.

### Starting prior: Numerical example {#sec:adp}

```{r figpriors, fig.cap="\\label{fig:figpriors} Age-dependent starting priors for the D-score at the ages of 1, 15 and 24 months", fig.height = 4}
#example from the adp function in ggplot:
qp <- -10:80
adp_dutch <- function(t, qp = -10:80) {
  mu <- dscore:::count_mu_dutch(t)
  dnorm(qp, mean = mu, sd = 5)
}

p1m <- data.frame(qp = qp, month = rep(1, length(qp)), p = adp_dutch(1/12))
p15m <- data.frame(qp = qp, month = rep(15, length(qp)), p = adp_dutch(15/12))
p24m <- data.frame(qp = qp, month = rep(24, length(qp)), p = adp_dutch(24/12))

dataprior <- rbind(p1m, p15m, p24m) %>%
  mutate(month = as.factor(month)) %>%
  dplyr::filter(p > 0.00001)

p <- ggplot(dataprior, aes(qp, p, group = month)) +
  theme(legend.position = c(0.05, 0.95), legend.justification = c(0, 1)) +
  geom_path(aes(colour = month)) +
  coord_cartesian(xlim = c(-10, 80)) +
  scale_y_continuous(name = "Density", limits = c(0, 0.3)) +
  scale_x_continuous(name = "D-score") +
  labs(colour = "Age (in months)") +
  scale_colour_manual(values = brewer.pal(12, "Paired")[c(1, 3, 5)])
p
```

Figure \@ref(fig:figpriors) illustrates starting distributions (priors) chosen according to the principles set above for the ages of 1, 15 and 24 months. As expected, the assumed ability of an infant aged one month is much lower than that of a child aged 15 months, which in turn is lower than the ability of a toddler aged 24 months. The green distribution for 15 months corresponds to the normal distribution $N(53.6, 5)$.

Another choice that we need to make is the grid of points on which we calculate the prior and posterior distributions. Figure \@ref(fig:figpriors) uses a grid from -10$D$ to +80$D$, with a step size of 1$D$. These are fixed *quadrature points*, and there are 91 of them. While these quadrature points are sufficient to estimate $D$-score for ages up to 2.5 years, it is wise to extend the range for older children with higher $D$-scores.

### EAP algorithm {#sec:EAP}

The algorithm for estimating the $D$-score is known as the Expected a posteriori (EAP) method, first described by @bock1982. Calculation of the $D$-score proceeds item by item. Suppose we have some vague and preliminary idea about the distribution of $D$, the starting prior (c.f. section \@ref(sec:startingprior)), based on age. The procedure uses Bayes rule to update this prior knowledge with data from the first item (using the child's FAIL/PASS score and the estimated item difficulty) to calculate the posterior. The next step uses this posterior as prior before processing the next item, and so on. The procedure stops when the item pool is exhausted. The order in which items enter does not matter for the result. The $D$-score is equal to the mean of the posterior calculated after the last question.

### EAP algorithm: Numerical example

Suppose we measure two boys aged 15 months, David and Rob, by the DDI. David passes the first four milestones but does not complete the test. Rob completes the test but fails on two out of five items.

```{r datadavidandrob}
items <- c("ddifmd011", "ddifmm012", "ddicmm037", "ddigmm066", "ddigmm067")
ib <- model$itembank %>%
  rename(delta = tau) %>%
  filter(item %in% items) %>%
  dplyr::select(item, label, delta)
ib <- ib[c(2, 3, 1, 4, 5), ]
dr <- data.frame(ib, 
                  David = c(1, 1, 1, 1, NA),
                  Rob = c(1, 0, 1, 1, 0))
kable(dr, caption = "Scores of David and Rob on five milestones from the DDI", 
      row.names = FALSE, col.names = c("Item", "Label", "Delta", "David", "Rob"))
```
&nbsp;

Table \@ref(tab:datadavidandrob) shows the difficulty of each milestone (in the column labelled "Delta"), and the responses of David and Rob for the standard five DDI milestones for the age of 15 months.

The mean $D$-score for Dutch children aged 15 months is 53.6$D$, so the milestones are easy to pass at this age, with the most difficult is `ddicmm037`. David passed all milestones but has no score on the last. Rob fails on `ddifmm012` and `ddigmm067`. How do we calculate the $D$-score for David and Rob?

```{r davidplot, fig.height = 12, fig.cap = '(ref:davidplot)'}
qp <- -10:80

# David
david <- matrix(NA, nrow = length(qp), ncol = 10, 
                dimnames = list(NULL, c(paste0("prior", 1:5), paste0("post", 1:5))))
data_david <- data.frame(
  age = rep(15/12, 6),
  ddifmd011 = c(NA,  1,  1,  1,  1,  1),
  ddifmm012 = c(NA, NA,  1,  1,  1,  1),
  ddicmm037 = c(NA, NA, NA,  1,  1, 1),
  ddigmm066 = c(NA, NA, NA, NA,  1,  1),
  ddigmm067 = c(NA, NA, NA, NA, NA, NA)
)

post <- dscore::dscore_posterior(data = data_david, qp = -10:80, prior_mean = ".dutch")

david[, "prior1"] <- post[1, ]
david[, c("post1", "prior2")] <- post[2, ]
david[, c("post2", "prior3")] <- post[3, ]
david[, c("post3", "prior4")] <- post[4, ]
david[, c("post4", "prior5")] <- post[5, ]
david[, "post5"] <- post[6, ]

# Rob
rob <- matrix(NA, nrow = length(qp), ncol = 10, 
              dimnames = list(NULL, c(paste0("prior", 1:5), paste0("post", 1:5))))
data_rob <- data.frame(
  age = rep(15/12, 6),
  ddifmd011 = c(NA,  1,  1,  1,  1, 1),
  ddifmm012 = c(NA, NA,  0,  0,  0, 0),
  ddicmm037 = c(NA, NA, NA,  1,  1, 1),
  ddigmm066 = c(NA, NA, NA, NA,  1, 1),
  ddigmm067 = c(NA, NA, NA, NA, NA, 0)
)

post <- dscore::dscore_posterior(data = data_rob, qp = -10:80, prior_mean = ".dutch")

rob[, "prior1"] <- post[1, ]
rob[, c("post1", "prior2")] <- post[2, ]
rob[, c("post2", "prior3")] <- post[3, ]
rob[, c("post3", "prior4")] <- post[4, ]
rob[, c("post4", "prior5")] <- post[5, ]
rob[, "post5"] <- post[6, ]

# create plotting data
plotdata <- expand.grid(x = qp, item = items, 
                        type = c("Prior", "Posterior"), 
                        person = c("David", "Rob"))
plotdata <- cbind(plotdata, y = c(as.vector(david), as.vector(rob)))
plotdata <- plotdata %>%
  dplyr::filter(y > 0.00001)

p <- ggplot(plotdata, aes(x = x, y = y)) +
  theme(legend.position = "bottom") + 
  geom_path(aes(colour = type)) +
  facet_grid(item ~ person) +
  coord_cartesian(xlim = c(40, 70)) +
  scale_y_continuous(name = "Density", limits = c(0, 0.32)) +
  scale_x_continuous(name = "D-score") +
  labs(colour = "Type of distribution") + 
  scale_colour_manual(values = brewer.pal(12, "Paired")[c(3, 4)])
p
```
(ref:davidplot) $D$-score distribution for David and Rob before (prior) and after (posterior) a milestone is taken into account.

Figure \@ref(fig:davidplot) shows how the prior transforms into the posterior after we successively feed the measurements into the calculation. There are five milestones, so the calculation comprises five steps:

1. Both David and Rob pass `ddifmd011`. The prior (light green) is the same as in Figure \@ref(fig:figpriors). After a PASS, the posterior will be located more to the right, and will often be more peaked. Both happen here, but the change is small. The reason is that a PASS on this milestone is not very informative. For a child with a true $D$-score of 53$D$, the probability of passing `ddifmd011` is equal to `r plogis((53 - 46) / model$transform[2])`. If passing is so common, there is not much information in the measurement.

2. David passes `ddifmm012`, but Rob does not. Observe that the prior is identical to the posterior of `ddifmd011`. For David, the posterior is only slightly different from the prior, for the same reason as above. For Rob, we find a considerable change to the left, both for location (from 54.3$D$ to 47.1$D$) and peakedness. This one FAIL lowers Rob's score by 7.2$D$.

3. Milestone `ddicmm037` is more difficult than the previous two milestones, so a pass on `ddicmm037` does have a definite effect on the posterior for both David and Rob.

4. David's PASS on `ddigmm066` does not bring any additional information, so his prior and posterior are virtually indistinguishable. For Rob, we find a slight shift to the right.

5. There is no measurement for David on `ddigmm067`, so the prior and posterior are equivalent. For Rob, we observe a FAIL, which shifts his posterior to the left.

We calculate the $D$-score as the mean of the posterior. David's $D$-score is equal to 55.7$D$. Note that the measurement error, as estimated from the variance of the posterior, is relatively large. Rob's $D$-score is equal to 47.7$D$, with a much smaller measurement error. This result is consistent with the design principles of the DDI, which is meant to detect children with developmental delay.

The example illustrates that the quality of the $D$-score depends on two factors, the match between the true (but unknown) $D$-score of the child and the difficulty of the milestone.

### Technical observations on $D$-score estimation

* Administration of a too easy set of milestones introduces a *ceiling* with children that pass all milestones, but whose true $D$-score could extend well beyond the maximum. Depending on the goal of the measurement, this may or may not be a problem.

* The specification of the prior and posterior distributions requires a set of quadrature points. The quadrature points are taken here as the static and evenly-spaced set of integers between -10 and +80. Using other quadrature points may affect the estimate, especially if the range of the quadrature points does not cover the entire $D$-score range.

* The actual calculations are here done item by item. A more efficient method is to handle all responses at once. The result will be the same.

## Age-conditional references {#sec:reference}

### Motivation

The last step involves estimation an age-conditional reference distribution for the $D$-score. This distribution can be used to construct growth charts that portray the normal variation in development. Also, the references can be used to calculate age-standardized $D$-scores, called DAZ, that emphasize the location of the measurement in comparison to age peers.

Estimation of reference centiles is reasonably standard. Here we follow @vanbuuren2014 to fit age-conditional references of the $D$-score for boys and girls combined by the LMS method. The LMS method by @cole1992 assumes that the outcome has a normal distribution after a Box-Cox transformation. The reference distribution has three parameters, which model respectively the location ($M$), the spread ($S$), and the skewness ($L$) of the distribution. Each of the three parameters can vary smoothly with age.

### Estimation of the reference distribution

The parameters are estimated using the BCCG distribution of `gamlss 5.1-3` [@stasinopoulos2007] using cubic splines smoothers. The final solution used a log-transformed age scale and fitted the model with smoothing parameters $\mathrm{df}(M)=2$, $\mathrm{df}(S)=2$ and $\mathrm{df}(L)=1$.

Figure \@ref(fig:smoccda) plots the $D$-scores together with five grey lines, corresponding to the centiles -2SD (P2), -1SD (P16), 0SD (P50), +1SD (P84) and +2SD (P98). The area between the -2SD and +2SD lines delineates the $D$-score expected if development is healthy. Note that the shape of the reference is quite similar to that of weight and height, with rapid growth occurring in the first few months.

```{r reftable}
op <- options()
options(digits = 7)
reference <- dplyr::select(dscore::get_reference("dutch"), age, mu, sigma, nu) %>%
  rename(M = mu,
         S = sigma, 
         L = nu)
knitr::kable(reference,
             caption = "Dutch reference values for the D-score: M-curve (median), S-curve (spread) and L-curve (skewness).") %>% 
  kableExtra::kable_styling(full_width = TRUE) %>%
  kableExtra::scroll_box(height = "300px")
```
&nbsp;

Table \@ref(tab:reftable) defines age-conditional references for Dutch children as the $M$-curve (median), $S$-curve (spread) and $L$-curve (skewness) by age. This table can be used to calculate centile lines and $Z$-scores.

The references are purely cross-sectional and do not account for the correlation structure between ages. For prediction purposes, it is useful to extend the modelling to include velocities and change scores.

### Conversion of $D$ to DAZ, and vice versa

Suppose that $M_t$, $S_t$ and $L_t$ are the parameter values at age $t$. @cole1988 shows that the transformation

$$Z=\frac{(D_t/M_t)^{L_t}-1}{L_t S_t}$$

converts measurement $D_t$ into its normal equivalent deviate $Z$. If $L_t$ is close to zero, we use

$$Z=\frac{\ln(D_t/M_t)}{S_t}$$

We may derive any required centile curve from Table \@ref(tab:reftable). First, choose $Z_\alpha$ as the $Z$-score that delineates $100\alpha$ per cent of the distribution, for example, \ $Z_{0.05}=-1.64$. The $D$-score that defines the $100\alpha$ centile is equal to

$$D_t(\alpha) = M_t (1+L_t S_t Z_\alpha)^{1/L_t}$$

If $L_t$ is close to zero, we use

$$D_t(\alpha)= M_t \exp(S_t Z_\alpha).$$
