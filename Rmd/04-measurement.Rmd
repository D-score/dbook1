# $D$-score: A unit to quantify general child development {#ch:newmodel}

Chapter \@ref(ch:history) provided historic background on the nature
of child development. Chapter \@ref(ch:threeways) discussed three
general quantification approaches. This chapter explains the concepts
for the unit-based approach, and how to arrive at the $D$-score scale.
The text uses Dutch data to illustration the process.

## The Dutch Development Instrument (DDI) {#sec:ddi}

### Setting

The Dutch Youth Health Care (YHC) routinely monitors development of
almost all children living in The Netherlands. During the first four
years, there are 13 scheduled visits. During these visits, the YHC
professionals evaluate - amongst others - growth and development of
the child.

The *Dutch Development Instrument* (DDI; in Dutch: *Van Wiechenschema*) 
is the standard instrument used to measure development
during the ages 0-4 years. The DDI consists of 
[75 milestones](https://www.ncj.nl/van-wiechen/kenmerken/). 
The instrument assesses three developmental domains:

1. Fine motor, adaptation, personality and social behavior;
2. Communication
3. Gross motor

The milestones are organized on two
[forms](https://www.ggdghorkennisnet.nl/?file=656&m=1310474916&action=file.download),
one for children aged 0-15 months, and another for children ages 15-54
months. The YHC professionals administer an age-appropriate subset at
each of the scheduled visits, thus building a 
*longitudinal developmental profile* for each child.

### Description of SMOCC study

The Social Medical Survey of Children Attending Child Health Clinics
(SMOCC) study is a a nationally representative cohort of 2,151
children born in The Netherlands during the years 1988â€“1989
[@herngreen1994]. The study monitored child development using
observations made on the DDI during 10 visits in the first 30 months 
of life.

The standard set in the DDI consists of relatively easy milestones
that 90 percent of the children can pass at the scheduled age. This
set of designed to have maximal sensitivity for picking up delays in
development. A special feature of the SMOCC study was the inclusion of
additional, and more difficult, milestones beyond the standard set.
The additional milestones are taken as the set for the next time
point. The success percentage on additional milestones is about 50
percent.

### Codebook of Dutch Development Instrument 0-15 months

```{r smoccitems, echo = FALSE}
library(gseddata)
meta <- get_itemtable(get_itemnames(instrument = "ddi")) %>%
  dplyr::select(item, domain, label) %>%
  mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                          "fm" = "Fine motor",
                                          "gm" = "Gross motor")))
options(knitr.table.format = "html") 
kable(meta, 
      caption = "Codebook of DDI, 0-15 months",
      row.names = FALSE, 
      col.names = c("Item", "Domain", "Label")) %>%
  kableExtra::kable_styling() %>%
  kableExtra::scroll_box(width = "100%", height = "400px")
```

Table \@ref(tab:smoccitems) shows the 57 milestones from the DDI for
ages 0 - 30 months. The response to each milestones is either a 
PASS (1) or a FAIL (0). Missing values are allowed.

## Probability of passing DDI milestones given age

```{r smoccpa, echo = FALSE, fig.cap = '(ref:smoccpa)', fig.height = 4}
smocc <- get_data(cohorts = 53)
items <- get_itemnames(smocc)

# define data for rug plot
data_rug <- smocc$itm %>%
  mutate(agemos = round(12 * agedays / 365.25), 3) %>%
  dplyr::select(item, value, agemos)

# calculate summary statistics
pass <- data_rug %>%
  mutate(agegp = cut(.data$agemos, breaks = seq(0, 60, 1))) %>%
  group_by(item, agegp) %>%
  summarise(p = round(100 * mean(.data$value, na.rm = TRUE)),
            a = mean(.data$agemos, na.rm = TRUE),
            n = n()) %>%
  ungroup() %>%
  left_join(dmetric::get_itemtable(items = items, package = "gseddata"), by = "item") %>% 
  filter(n >= 5) %>%
  arrange(.data$item, a) %>%
  mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                          "fm" = "Fine motor",
                                          "gm" = "Gross motor")))

plot <- ggplot(pass, aes(a, p, group = item, colour = domain,
                         label = label)) +
  scale_x_continuous("Age (in months)", limits = c(0, 30),
                     breaks = seq(0, 28, 4)) +
  scale_y_continuous("% pass", breaks = seq(0, 100, 20),
                     limits = c(0, 100)) + 
  theme_light() +
  geom_line(size = 0.3) + 
  geom_point(size = 1.0) +
  theme(legend.position = "none")
py <- plotly::ggplotly(plot, tooltip = c("item", "label"))
py
```

(ref:smoccpa) Empirical percentage of passing each milestone in the
DDI against age (Source: SMOCC data, $n$ = 2151, 9 occasions).

Figure \@ref(fig:smoccpa) summarizes the response obtained on each
milestone as a curve against age. The percentage of pass scores
increases with age for all milestones. Note that curves on the left
have steeper slopes than those on the right, thus indicating that
development is faster for younger children.

The item are colored by domain. In general, domains are well mixed
across age, though around some ages, e.g., at 4 months, multiple
milestones from the same domain appear.

## Rasch model



## Estimation of $D$-score

With the SMOCC dataset we can compare the D-scores calculated by making use of calibrated milestones (the current wave milestones) with the D-scores calculated by making use of non-calibrated milestones (the next wave milestones). These D-scores for children of the age of 2 and 3 months (wave 2 and 3) are plotted against IQ at 5 years in figure \@ref(fig:dscoresnw). The continuous variable IQ at 5 years allows for nice visualization of the variation in D-scores. Moreover, the densities of the D-score are given at the bottom of the plots showing the distribution of the values of the D-score.


## Estimation of the $D$-score

To explain how
the D-score is calculated and demonstrate the use of the D-score
package two example children, both of the age of 15 months, are used.
One of the example children is able to do all items of his/her age,
and the other example child is not able to do all items of his/her
age. In this way, we can show how different scores on a item affect
the D-score.

So for example, for a child of the age of 15 months the Dutch Developmental Instrument consists of the following six items: puts cube in and out of a box, plays 'give and take', crawls (abdomen off the floor), walks along, understands a few words, and says 2 'sound-words' with comprehension. For each of these six items it is noted whether the child was able to perform this item. An example of the results can be found in table \@ref(tab:tableWS), in which *child 1* was able to perform all items and *child 2* was able to perform four of the six items. Based on these scores we can calculate the dscore for both these children.



## Measurement model {#sec:measurementmodel}

Uni-dimensional measurement models attempt to explain systematic
patterns in the observed data through their relation to a single
underlying variable. For example, we may find that the observed data
are highly correlated, but that this correlation disappears within
groups of children that have the same value on the latent variable. In
that case, we have absorbed the common information in the variables
into a single score that captures the relevant information.

It may be that the measurement model does not fit the data
sufficiently well. There are various strategies how to deal with this
issue. We may extend the measurement model so that it will be able to extract
additional features from the data. Alternatively, we may search for a
subset of the data (usually the items) that does fit the model. These
are very different strategies that have led to heated debates among
psychometricians. See @engelhard2013 for an overview.

Most measurement models used today are probabilistic. These models
express the probability of passing an item as a function of the
*difference* between the person's ability and the item's difficulty. A
person with low ability will almost surely fail a difficult item,
whereas a highly able person will almost surely pass an easy item. One may also use the model to compare persons or items.

## Logit scale {#sec:logit}

Let us now introduce a few symbols. We adopt the notation used in
@wright1982. See Chapter \@ref(ch:notation) for a complete list.

Let $\beta_n$ be the true (but unknown) developmental score of a child
at the time of measurement. The more generic term for $\beta_n$ is the
child's *ability*. Let $\delta_i$ be the true (but unknown)
*difficulty* of an item. Thus, Figure \@ref(fig:lineplot) shows three
$\beta_n$'s and four $\delta_i$'s.

Differences on the latent scale are commonly expressed as "logistic
units", or  *logits* [@berkson1944]. If the person ability $\beta_n$
and the item difficulty $\delta_i$ coincide, then the
*ability-difficulty gap* $\beta_n - \delta_i = 0$, and the person
has an probability of 0.5 of passing the item. In `R` we can calculate
this probability by the inverse-logit (or *logistic* function) as

```{r logit0}
plogis(0)
```

Likewise, if $\beta_n - \delta_i = 1$, then person ability is larger than 
item difficulty, and we find a higher the probability of passing:

```{r logit1}
plogis(1)
```

```{r logisticplot, echo = FALSE, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:logisticplot)', width = "80%"}
pkg <- c("ggplot2", "RColorBrewer")
loaded <- sapply(pkg, require, character.only = TRUE, 
                 warn.conflicts = FALSE, quietly = TRUE)
options(knitr.kable.NA = "?")

x <- seq(-5, 5, 0.25)
items <- data.frame(
  Items = c(rep(c("C", "B", "A", "D", "E"), times = c(4, 2, length(x), length(x), length(x)))),
  beta = c(-5, 1, 1, +5,  -5,  +5, x, x, x),
  pass = c( 0, 0, 1,  1, 0.3, 0.3,
           plogis(x),
           plogis(0.6 * (x + 1)),
           smooth.spline(x = x, y = plogis(c(x[1:15], rep(x[16], 10), x[26:41])), df = 8)$y))
ggplot(subset(items, Items == "A"), aes(x = beta, y = 100 * pass, group = Items, colour = Items)) +
  geom_line(lwd = 0.55) + 
  scale_x_continuous("logits", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(palette = "Set1", labels = c("A: Logistic", "B: Constant", "C: Step", "D: 2PL", "E: Monotone")) + 
  theme_light() + 
  theme(legend.position = c(0.05, 0.95), legend.justification = c(0, 1))
```

(ref:logisticplot) Standard logistic curve. Percentage of children passing an item for a given ability-difficulty gap $\beta_n - \delta_i$.

Figure \@ref(fig:logisticplot) shows how the percentage that pass the item varies in terms of the ability-difficulty gap $\beta_n - \delta_i$. The gap  can vary either by $\beta_n$ or $\delta_i$, so we may use the graph in two ways:

- To find the probability of passing various items for a child with ability $\beta_n$. If $\delta_i = \beta_n$ then $\pi_{ni} = 0.5$. If $\delta_i < \beta_n$ then $\pi_{ni} < 0.5$, and if $\delta_i > \beta_n$ then $\pi_{ni} > 0.5$.

- To find the probability of passing a given item $\delta_i$ for children that vary in ability. If $\beta_n = delta_i$ then $\pi_{ni} = 0.5$. If $\beta_n < \delta_i$ then $\pi_{ni} < 0.5$, and if $\beta_n > \delta_i$ then $\pi_{ni} > 0.5$.

### Item response functions

The standard logistic function is by no means the only possibility to model the relation between the latent variable and the probability of
passing an item. The *item response function* of an item describes the probability of passing the item at each ability level.

```{r irfplot, echo = FALSE, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:irfplot)'}
ggplot(items, aes(x = beta, y = 100 * pass, group = Items, colour = Items)) +
  geom_line(lwd = 0.75) + 
  scale_x_continuous("Child ability (logits)", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(palette = "Set1", labels = c("A: Logistic", "B: Constant", "C: Step", "D: 2PL", "E: Monotone")) + 
  theme_light() + 
  theme(legend.position = c(0.05, 0.95), legend.justification = c(0, 1))
```

(ref:irfplot) Item response functions for five hypothetical items,
each demonstrating a positive relation between ability and probability
to pass.

Figure \@ref(fig:irfplot) illustrates several other possibilities. Let us consider five hypothetical items, A-E. Note that the horizontal axis now refers to ability, instead of ability-item gap in \@ref(fig:logisticplot).

- A: Item A is the logistic function discussed in Section
\@ref(sec:logit).

- B: For item B, the probability of passing is constant at 30 percent.
This 30 percent is not related to ability. This item does not measure
ability, and only adds to the noise. It is a bad item for measurement.

- C: Item C is step function centered at an ability level of 1, so *all*
children with an ability below 1 logit fail, and *all* children with
ability above 1 pass. This is the ideal item for discriminating
children with an abilities above and below 1. The item is not
sensitive to differences at other ability levels, and often not so
realistic in practice.

- D: Like A, item D is a smoothly increasing logistic function, but it
has an extra parameter that allows it to vary its slope (or
discrimination). The extra parameter can make the curve steeper (more
discriminatory) than the red curve, in the limit approaching a step
curve. It can also become shallower (less discriminatory) than the red
curve (as plotted here), in the limit approaching a constant curve
(item B). Thus, item D generalizes items A, B or C.

- E: Item E is even more general in the sense that it need not be
logistic, but a general monotonically increasing function. As plotted,
the item is insensitive to abilities between -1 and 0 logits, and more
sensitive to abilities between 0 to 2 logits.

These are just some examples of how the relation between the child's
ability and passing probability could look. In practice, the curves
need not start at 0 percent or end at 100 percent. They could also be
U-shaped, of have other non-monotonic forms. See @coombs1964 for a
thorough overview of such models. However, most models are restricted to shapes A-D.



### 



we know the score on one or more items, and the difficulties of these
items, we may calculate the position of the person on the latent
variable.



### Criteria for invariant measurement

Here we assume that the latent
variable has a constant unit, so interpretation of the same
difference is identical across the entire scale. 

Measurement is the process of assigning numbers by rules to a set of
persons or objects. This definition is a little liberal. In order to
be useful the process of assigning numbers must be bound by some
imperatives. In this booklet, we strive to achieve *invariant
measurement*, a very strict form of measurements that is subject to
the following requirements (@engelhard2013, p. 14):

1. *Item-invariant measurement of persons*: The measurement of persons
must be independent of the particular items that happen to be used for
the measuring.

2. *Non-crossing persons response functions*: A more able person must
always have a better chance of success on an item that a less able
person.

3. *Person-invariant calibration of test items*: The calibration of
the items must be independent of the particular persons used for
calibration.

4. *Non-crossing item response functions*: Any person must have a
better chance of success on an easy item than on a more difficult
item.

5. *Unidimensionality*: Items and persons must be simultaneously
located on a single underlying latent variable.

A statistical model that conforms to these five requirements is said
to be an *ideal-type model*. There are only very few ideal-type
models. An ideal-type model isn't changed to fit the data, but the
data (items and persons) are selected to fit the ideal-type model.

The need for the five requirements for invariance is not universally
shared. In particular, a substantial group of statisticians questions
the need for requirements 2 and 4, especially the words "always" and
"any", and may opt for more flexible models that do not strictly
adhere to the invariance conditions 2 and 4. There are also more
flexible models that assume a multi-dimensional instead of a
unidimensional latent variable. Some investigators question all
requirements, and would rather not be restricted and place a high
value to a good fit to all data.


### Person response functions

We now switch the roles of persons and items, and construct a function
that tells us how likely it is that a single person can pass an item, 
or more commonly, a set of items. 

Let us continue with items A, C and D from Figure \@ref(fig:irfplot), and 
calculate the response function for three children, respectively with 
abilities $\beta_1 = -2$, $\beta_2 = 0$ and $\beta_3 = 2$.

```{r prfplot, echo = FALSE, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:prfplot)'}
x <- c(seq(-5.00, -2.25, 0.25), -2.001, -2, -1.999, 
       seq(-1.75, -0.25, 0.25), -0.001,  0,  0.001,
       seq( 0.25,  1.75, 0.25),  1.999,  2,  2.001,
       seq( 2.25,  5.00, 0.25))
A1 <- c(rep(1, 23), 0.5, rep(0, 23))
C1 <- 1 - plogis(x)
D1 <- 1 - plogis(0.6 * (x + 1))
ACD1 <- (A1 + C1 + D1) / 3

A2 <- c(rep(1, 33), 0.5, rep(0, 13))
C2 <- 1 - plogis(x - 2)
D2 <- 1 - plogis(0.6 * (x - 1))
ACD2 <- (A2 + C2 + D2) / 3

A3 <- c(rep(1, 13), 0.5, rep(0, 33))
C3 <- 1 - plogis(x + 3)
D3 <- 1 - plogis(0.6 * (x + 4))
ACD3 <- (A3 + C3 + D3) / 3

data <- data.frame(delta = x,
                   person = rep(c("-2", "0", "+2"), each = 47),
                   pass = c(ACD3, ACD1, ACD2))
ggplot(data, aes(x = delta, y = 100 * pass, group = person, colour = person)) +
  geom_line(lwd = 0.75) + 
  scale_x_continuous("Item difficulty (logits)", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(name = "Person ability", palette = "Set1", limits = c("-2", "0", "+2")) + 
  theme_light() + 
  theme(legend.position = c(0.8, 0.6), legend.justification = c(0, 0)) +
  annotate("text", x = -4.5, y = 15, label = "Easy items", fontface = "bold") + 
  annotate("text", x =  4.5, y = 15, label = "Hard items", fontface = "bold")
```

(ref:prfplot) Person response functions for three children with abilities 
-2, 0 and +2, using a small test of items A, C and D.

Figure \@ref{fig:prfplot} presents the person response functions from
three persons with abilities of -2, 0 and +2 logits. The functions are
calculated as the average of response probabilities on items A, C and
D. Thus, on average, we expect that child 1 will pass an easy item of
difficulty -3 in about 60 percent of the time, whereas for an
intermediate item of difficulty of -1 the passing probility would be
10 percent. For child 3, with a higher ability, these probabilities
are quite different: 97% and 90%. The substantial drop in the middle
of the curve is caused by the step function of item A. 

Requirement 2 states that the success probability should be higher for
persons with a higher ability level. This is indeed the case here, but
there are also item response functions for which requirement 2 does
not hold.

### What is a test?

A set of items forms a test. The primary reason for administering a
test rather than a separate item is to improve the precision of the
measurement. The scores on the set of items (rather than the score on
a single item) can be combined into an overall score. Of course,
combining scores can only make sense if these items measure the same
underlying construct.

In principle, the five items A-E in Figure \@ref(fig:irfplot) could
form a test. This would not be an ideal test though, since this test
would violate requirement 4. We know that the difficulty of item A is
equal to +1 logits, and the difficulty of item C is 0 logits, so item
C is easier than item A. Requirement 4 says that persons should have a
higher chance of passing C. This is true indeed for persons having an
ability lower than +1 logits. However, for a person with ability +2
logits, the probability of passing A is higher than passing C, hence
requirement 4 does not hold for any test that holds both items A and 
C.


### Interval scale

The important property is that $\beta_1$, $\beta_2$ and $\beta_3$ are
all on the same scale, and hence can be compared in a sensible way. In
particular, suppose that $\beta_2 - \beta_1 = \beta_3 - \beta_2$, we
might say that the difference between ability $\beta_1$ and $\beta_2$
is the same the difference between abilities $\beta_2 - \beta_3$. This 
is the essential property of an interval scale.



### Family of item response theory models

*Ideal-type models*:

1. Guttman scalogram model (@guttman1950)

2. Rasch model (@rasch1960) and extensions (@wright1982, @andrich1988)

3. Mokken scaling model (@mokken1971).

The Guttman and Mokken model yield an ordinal latent scale, while the 
Rasch model yields an interval scale (with a constant unit).


## Comparison to classic age-based approach {#comparisonagebased}

EXAMPLES OF AGE-BASED MEASUREMENT

Let the $Y_j$ contain the scores on the $j$-th developmental item, where $j = 1, \dots, p$. 
For the moment, let us assume that all items are binary, so that 
$Y_j = 0$ indicates a fail, and $Y_j = 1$ indicates a pass. 
Suppose we are interested in studing the relationship between age, denoted by 
variable $X$, and development as measured through items $Y_1, \dots, Y_p$.

The joint distribution $P(Y_1, \dots, Y_p, X)$ contains all relevant 
information for this problem. Age-based measurement is an attempt to model 
this joint distribution by breaking it down into $p$ conditional distributions:
$$
P(Y_1 | X)\\
\vdots\\
P(Y_p | X)\\
$$

each of which describes how the probability of passing changes with age. 
For example, @drachler2007 formulated the model as a logistic regression 
model on the logarithm of age:

$$ 
\ln \frac{P(Y_j=1)}{P(Y_j=0)} = \alpha_j + \beta_j\ln X
$$

For this model, the age at which 50\% of the children pass item $j$ 
can be calculated as to $\exp(-\alpha_j/\beta_j)$. Since older children are 
expected to be more mature, this parameter is typically 
interpreted as the difficulty of the item. The slope parameter 
$\beta_j$ indicates how rapidly the probability of passing 
rises with age. Items with high $\beta_j$ have a great power to discriminate 
developmental status well within a small age range. It is straightforward
to calculate any other age-percentiles, for example, the ages 
at which probabilities 10\% or 90\% of the sample pass the item.
Table~2 in @drachler2007 reports these statistics for the Denver 
developmental test.

While the idea of breaking up the test into separate items
is productive, age-based measurement has severe weaknesses. 

1. The concepts of age and development are not separated, so we 
cannot interpret the difficulty of an item without age. 
It would be more convenient, and conceptually clearer, if 
item difficulty could be a free-standing concept.

2. The models are fitted separately for each $Y_j$. Nothing 
is specified how the items relate to each other, so in principle, 
any variable that changes with age (e.g. child had first birthday) could 
qualify as a developmental item. It would be better of the 
procedure would start from a model about how the items should 
relate to each other. 

3. The intercept and slope estimates are dependent on 
the sample. A sample consisting of children of low ability
would give different estimates than a sample of children with
high ability. Calibration of test items is not person-invariant. 
It would be preferable if the difficulty estimates
were independent of the sample used to estimate them. 

4. Because of the introduction of slopes in the logistic model
a more able person may have a lower success probability for some
items than a less able person. It would be preferable if 
more able persons have a better succes rate on all items.

In general, we expect that this probability increases with ability
(requirement 2). Note that this formulation differs from that given in
Section \@ref(sec:agebased), where the probability was said to
increase in age, not ability. We will address this crucial difference
in more detail in Section xx.


## Why some prefer the Rasch model

### The model as ideal

### Perfect symmetry

### Specific objectivity (example)

### Simplicity
